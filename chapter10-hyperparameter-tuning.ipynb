{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper parameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What can you tweak in neural network:\n",
    "\n",
    "1. Number of layers\n",
    "2. Number of Neurons\n",
    "3. Type of activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import reciprocal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = fetch_california_housing()\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "housing.data, housing.target)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "X_train_full, y_train_full)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "X_new = X_test[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[8]):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
    "\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    optimizer = keras.optimizers.SGD(lr=learning_rate)\n",
    "    model.compile(loss=\"mse\", optimizer=optimizer)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8t/3rnys97s4mj60s_wk489wkp80000gn/T/ipykernel_16318/3313595958.py:2: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)\n",
      "/Users/soomin/.pyenv/versions/miniforge3-4.10.1-5/envs/handson-conda/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363/363 [==============================] - 0s 487us/step - loss: 1.2378 - val_loss: 0.6579\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 0s 399us/step - loss: 0.6133 - val_loss: 0.5629\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 0s 400us/step - loss: 0.5496 - val_loss: 0.5111\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 0s 397us/step - loss: 0.5140 - val_loss: 0.4906\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 0s 398us/step - loss: 0.4923 - val_loss: 0.4663\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 0s 388us/step - loss: 0.4752 - val_loss: 0.4498\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 0s 395us/step - loss: 0.4622 - val_loss: 0.4375\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 0s 396us/step - loss: 0.4546 - val_loss: 0.4274\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 0s 391us/step - loss: 0.4456 - val_loss: 0.4233\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 0s 395us/step - loss: 0.4405 - val_loss: 0.4161\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 0s 411us/step - loss: 0.4341 - val_loss: 0.4098\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 0s 404us/step - loss: 0.4296 - val_loss: 0.4037\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 0s 395us/step - loss: 0.4247 - val_loss: 0.4049\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 0s 388us/step - loss: 0.4217 - val_loss: 0.3999\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 0s 380us/step - loss: 0.4188 - val_loss: 0.3940\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 0s 386us/step - loss: 0.4149 - val_loss: 0.3905\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 0s 389us/step - loss: 0.4108 - val_loss: 0.3917\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 0s 380us/step - loss: 0.4085 - val_loss: 0.3855\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 0s 388us/step - loss: 0.4063 - val_loss: 0.3817\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 0s 397us/step - loss: 0.4035 - val_loss: 0.3796\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 0s 491us/step - loss: 0.4004 - val_loss: 0.3801\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 0s 388us/step - loss: 0.3987 - val_loss: 0.3744\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 0s 380us/step - loss: 0.3964 - val_loss: 0.3727\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 0s 386us/step - loss: 0.3955 - val_loss: 0.3710\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 0s 388us/step - loss: 0.3929 - val_loss: 0.3765\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 0s 389us/step - loss: 0.3914 - val_loss: 0.3688\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 0s 390us/step - loss: 0.3896 - val_loss: 0.3692\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 0s 390us/step - loss: 0.3879 - val_loss: 0.3889\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 0s 388us/step - loss: 0.3854 - val_loss: 0.3628\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 0s 392us/step - loss: 0.3837 - val_loss: 0.3610\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 0s 392us/step - loss: 0.3820 - val_loss: 0.3639\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 0s 385us/step - loss: 0.3814 - val_loss: 0.3575\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 0s 552us/step - loss: 0.3790 - val_loss: 0.3587\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 0s 391us/step - loss: 0.3779 - val_loss: 0.3549\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 0s 391us/step - loss: 0.3762 - val_loss: 0.3538\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 0s 393us/step - loss: 0.3750 - val_loss: 0.3537\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 0s 385us/step - loss: 0.3743 - val_loss: 0.3552\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 0s 386us/step - loss: 0.3723 - val_loss: 0.3559\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 0s 382us/step - loss: 0.3728 - val_loss: 0.3505\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 0s 390us/step - loss: 0.3700 - val_loss: 0.3510\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 0s 387us/step - loss: 0.3691 - val_loss: 0.3482\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 0s 384us/step - loss: 0.3679 - val_loss: 0.3761\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 0s 390us/step - loss: 0.3680 - val_loss: 0.3473\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 0s 392us/step - loss: 0.3668 - val_loss: 0.3454\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 0s 387us/step - loss: 0.3641 - val_loss: 0.3483\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 0s 393us/step - loss: 0.3631 - val_loss: 0.3472\n",
      "Epoch 47/100\n",
      "363/363 [==============================] - 0s 388us/step - loss: 0.3630 - val_loss: 0.3433\n",
      "Epoch 48/100\n",
      "363/363 [==============================] - 0s 384us/step - loss: 0.3617 - val_loss: 0.3413\n",
      "Epoch 49/100\n",
      "363/363 [==============================] - 0s 387us/step - loss: 0.3601 - val_loss: 0.3415\n",
      "Epoch 50/100\n",
      "363/363 [==============================] - 0s 393us/step - loss: 0.3620 - val_loss: 0.3403\n",
      "Epoch 51/100\n",
      "363/363 [==============================] - 0s 387us/step - loss: 0.3602 - val_loss: 0.3392\n",
      "Epoch 52/100\n",
      "363/363 [==============================] - 0s 384us/step - loss: 0.3579 - val_loss: 0.3387\n",
      "Epoch 53/100\n",
      "363/363 [==============================] - 0s 418us/step - loss: 0.3583 - val_loss: 0.3419\n",
      "Epoch 54/100\n",
      "363/363 [==============================] - 0s 569us/step - loss: 0.3571 - val_loss: 0.3382\n",
      "Epoch 55/100\n",
      "363/363 [==============================] - 0s 405us/step - loss: 0.3571 - val_loss: 0.3383\n",
      "Epoch 56/100\n",
      "363/363 [==============================] - 0s 400us/step - loss: 0.3550 - val_loss: 0.3366\n",
      "Epoch 57/100\n",
      "363/363 [==============================] - 0s 389us/step - loss: 0.3574 - val_loss: 0.3380\n",
      "Epoch 58/100\n",
      "363/363 [==============================] - 0s 387us/step - loss: 0.3554 - val_loss: 0.3386\n",
      "Epoch 59/100\n",
      "363/363 [==============================] - 0s 409us/step - loss: 0.3541 - val_loss: 0.3362\n",
      "Epoch 60/100\n",
      "363/363 [==============================] - 0s 419us/step - loss: 0.3531 - val_loss: 0.3370\n",
      "Epoch 61/100\n",
      "363/363 [==============================] - 0s 396us/step - loss: 0.3559 - val_loss: 0.3379\n",
      "Epoch 62/100\n",
      "363/363 [==============================] - 0s 388us/step - loss: 0.3571 - val_loss: 0.3363\n",
      "Epoch 63/100\n",
      "363/363 [==============================] - 0s 396us/step - loss: 0.3561 - val_loss: 0.3409\n",
      "Epoch 64/100\n",
      "363/363 [==============================] - 0s 392us/step - loss: 0.3607 - val_loss: 0.3355\n",
      "Epoch 65/100\n",
      "363/363 [==============================] - 0s 391us/step - loss: 0.3573 - val_loss: 0.3327\n",
      "Epoch 66/100\n",
      "363/363 [==============================] - 0s 386us/step - loss: 0.3492 - val_loss: 0.3334\n",
      "Epoch 67/100\n",
      "363/363 [==============================] - 0s 383us/step - loss: 0.3482 - val_loss: 0.3435\n",
      "Epoch 68/100\n",
      "363/363 [==============================] - 0s 389us/step - loss: 0.3493 - val_loss: 0.3358\n",
      "Epoch 69/100\n",
      "363/363 [==============================] - 0s 389us/step - loss: 0.3511 - val_loss: 0.3338\n",
      "Epoch 70/100\n",
      "363/363 [==============================] - 0s 386us/step - loss: 0.3517 - val_loss: 0.3325\n",
      "Epoch 71/100\n",
      "363/363 [==============================] - 0s 387us/step - loss: 0.3478 - val_loss: 0.3295\n",
      "Epoch 72/100\n",
      "363/363 [==============================] - 0s 382us/step - loss: 0.3468 - val_loss: 0.3311\n",
      "Epoch 73/100\n",
      "363/363 [==============================] - 0s 386us/step - loss: 0.3467 - val_loss: 0.3290\n",
      "Epoch 74/100\n",
      "363/363 [==============================] - 0s 383us/step - loss: 0.3463 - val_loss: 0.3288\n",
      "Epoch 75/100\n",
      "363/363 [==============================] - 0s 384us/step - loss: 0.3438 - val_loss: 0.3304\n",
      "Epoch 76/100\n",
      "363/363 [==============================] - 0s 478us/step - loss: 0.3440 - val_loss: 0.3298\n",
      "Epoch 77/100\n",
      "363/363 [==============================] - 0s 385us/step - loss: 0.3433 - val_loss: 0.3305\n",
      "Epoch 78/100\n",
      "363/363 [==============================] - 0s 462us/step - loss: 0.3440 - val_loss: 0.3297\n",
      "Epoch 79/100\n",
      "363/363 [==============================] - 0s 410us/step - loss: 0.3479 - val_loss: 0.3282\n",
      "Epoch 80/100\n",
      "363/363 [==============================] - 0s 405us/step - loss: 0.3459 - val_loss: 0.3305\n",
      "Epoch 81/100\n",
      "363/363 [==============================] - 0s 414us/step - loss: 0.3441 - val_loss: 0.3320\n",
      "Epoch 82/100\n",
      "363/363 [==============================] - 0s 557us/step - loss: 0.3420 - val_loss: 0.3323\n",
      "Epoch 83/100\n",
      "363/363 [==============================] - 0s 392us/step - loss: 0.3462 - val_loss: 0.3298\n",
      "Epoch 84/100\n",
      "363/363 [==============================] - 0s 388us/step - loss: 0.3462 - val_loss: 0.3279\n",
      "Epoch 85/100\n",
      "363/363 [==============================] - 0s 407us/step - loss: 0.3427 - val_loss: 0.3287\n",
      "Epoch 86/100\n",
      "363/363 [==============================] - 0s 424us/step - loss: 0.3452 - val_loss: 0.3247\n",
      "Epoch 87/100\n",
      "363/363 [==============================] - 0s 388us/step - loss: 0.3534 - val_loss: 0.3303\n",
      "Epoch 88/100\n",
      "363/363 [==============================] - 0s 448us/step - loss: 0.3427 - val_loss: 0.3301\n",
      "Epoch 89/100\n",
      "363/363 [==============================] - 0s 422us/step - loss: 0.3381 - val_loss: 0.3238\n",
      "Epoch 90/100\n",
      "363/363 [==============================] - 0s 392us/step - loss: 0.3408 - val_loss: 0.3232\n",
      "Epoch 91/100\n",
      "363/363 [==============================] - 0s 489us/step - loss: 0.3456 - val_loss: 0.3237\n",
      "Epoch 92/100\n",
      "363/363 [==============================] - 0s 625us/step - loss: 0.3454 - val_loss: 0.3220\n",
      "Epoch 93/100\n",
      "363/363 [==============================] - 0s 420us/step - loss: 0.3488 - val_loss: 0.3226\n",
      "Epoch 94/100\n",
      "363/363 [==============================] - 0s 387us/step - loss: 0.3405 - val_loss: 0.3257\n",
      "Epoch 95/100\n",
      "363/363 [==============================] - 0s 436us/step - loss: 0.3472 - val_loss: 0.3244\n",
      "Epoch 96/100\n",
      "363/363 [==============================] - 0s 436us/step - loss: 0.3415 - val_loss: 0.3299\n",
      "Epoch 97/100\n",
      "363/363 [==============================] - 0s 417us/step - loss: 0.3413 - val_loss: 0.3338\n",
      "Epoch 98/100\n",
      "363/363 [==============================] - 0s 406us/step - loss: 0.3419 - val_loss: 0.3294\n",
      "Epoch 99/100\n",
      "363/363 [==============================] - 0s 393us/step - loss: 0.3372 - val_loss: 0.3212\n",
      "Epoch 100/100\n",
      "363/363 [==============================] - 0s 426us/step - loss: 0.3356 - val_loss: 0.3285\n",
      "162/162 [==============================] - 0s 268us/step - loss: 0.3624\n",
      "1/1 [==============================] - 0s 62ms/step\n"
     ]
    }
   ],
   "source": [
    "# Wrapper for using the Scikit-Learn API with Keras models.\n",
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)\n",
    "keras_reg.fit(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    epochs=100,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    callbacks=[keras.callbacks.EarlyStopping(patience=10)]\n",
    ")\n",
    "mse_test = keras_reg.score(X_test, y_test)\n",
    "y_pred = keras_reg.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "164/242 [===================>..........] - ETA: 0s - loss: 5.3843 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/soomin/.pyenv/versions/miniforge3-4.10.1-5/envs/handson-conda/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 576us/step - loss: 4.6123 - val_loss: 2.6273\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 423us/step - loss: 1.6637 - val_loss: 1.1680\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 419us/step - loss: 0.8781 - val_loss: 0.7492\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 420us/step - loss: 0.6557 - val_loss: 0.6237\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 417us/step - loss: 0.5891 - val_loss: 0.5797\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 417us/step - loss: 0.5671 - val_loss: 0.5634\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 428us/step - loss: 0.5574 - val_loss: 0.5532\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 423us/step - loss: 0.5519 - val_loss: 0.5507\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 418us/step - loss: 0.5476 - val_loss: 0.5464\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 417us/step - loss: 0.5438 - val_loss: 0.5444\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 428us/step - loss: 0.5409 - val_loss: 0.5395\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 439us/step - loss: 0.5380 - val_loss: 0.5376\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 433us/step - loss: 0.5353 - val_loss: 0.5352\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 424us/step - loss: 0.5330 - val_loss: 0.5329\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 434us/step - loss: 0.5308 - val_loss: 0.5312\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 440us/step - loss: 0.5288 - val_loss: 0.5293\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 435us/step - loss: 0.5270 - val_loss: 0.5282\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 475us/step - loss: 0.5252 - val_loss: 0.5276\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 424us/step - loss: 0.5237 - val_loss: 0.5256\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 459us/step - loss: 0.5222 - val_loss: 0.5273\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 441us/step - loss: 0.5209 - val_loss: 0.5237\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 421us/step - loss: 0.5199 - val_loss: 0.5252\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 417us/step - loss: 0.5188 - val_loss: 0.5215\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 417us/step - loss: 0.5179 - val_loss: 0.5206\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 418us/step - loss: 0.5170 - val_loss: 0.5206\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 0.5163 - val_loss: 0.5227\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 420us/step - loss: 0.5153 - val_loss: 0.5197\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 416us/step - loss: 0.5150 - val_loss: 0.5223\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 416us/step - loss: 0.5141 - val_loss: 0.5246\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 522us/step - loss: 0.5137 - val_loss: 0.5239\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 417us/step - loss: 0.5130 - val_loss: 0.5246\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 423us/step - loss: 0.5127 - val_loss: 0.5241\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 418us/step - loss: 0.5124 - val_loss: 0.5200\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 429us/step - loss: 0.5117 - val_loss: 0.5168\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 419us/step - loss: 0.5117 - val_loss: 0.5208\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 424us/step - loss: 0.5110 - val_loss: 0.5185\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 416us/step - loss: 0.5108 - val_loss: 0.5163\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 416us/step - loss: 0.5107 - val_loss: 0.5167\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 415us/step - loss: 0.5105 - val_loss: 0.5191\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 413us/step - loss: 0.5102 - val_loss: 0.5226\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 425us/step - loss: 0.5099 - val_loss: 0.5198\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 420us/step - loss: 0.5097 - val_loss: 0.5198\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 423us/step - loss: 0.5097 - val_loss: 0.5218\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 425us/step - loss: 0.5094 - val_loss: 0.5222\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 413us/step - loss: 0.5092 - val_loss: 0.5205\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 412us/step - loss: 0.5094 - val_loss: 0.5208\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 410us/step - loss: 0.5090 - val_loss: 0.5190\n",
      "121/121 [==============================] - 0s 271us/step - loss: 0.5483\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.8587 - val_loss: 2.1910\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 430us/step - loss: 1.4930 - val_loss: 1.0471\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 422us/step - loss: 0.8700 - val_loss: 0.7344\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 925us/step - loss: 0.6940 - val_loss: 0.6406\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 753us/step - loss: 0.6382 - val_loss: 0.6060\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 535us/step - loss: 0.6166 - val_loss: 0.5901\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 413us/step - loss: 0.6052 - val_loss: 0.5799\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 410us/step - loss: 0.5970 - val_loss: 0.5720\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 411us/step - loss: 0.5901 - val_loss: 0.5650\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 415us/step - loss: 0.5843 - val_loss: 0.5589\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 430us/step - loss: 0.5788 - val_loss: 0.5541\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 413us/step - loss: 0.5739 - val_loss: 0.5486\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 409us/step - loss: 0.5695 - val_loss: 0.5444\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 409us/step - loss: 0.5654 - val_loss: 0.5407\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 410us/step - loss: 0.5617 - val_loss: 0.5376\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 438us/step - loss: 0.5583 - val_loss: 0.5345\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 415us/step - loss: 0.5553 - val_loss: 0.5314\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 413us/step - loss: 0.5526 - val_loss: 0.5290\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 415us/step - loss: 0.5500 - val_loss: 0.5263\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 409us/step - loss: 0.5477 - val_loss: 0.5247\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 414us/step - loss: 0.5454 - val_loss: 0.5230\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 415us/step - loss: 0.5437 - val_loss: 0.5219\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 410us/step - loss: 0.5418 - val_loss: 0.5199\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 412us/step - loss: 0.5404 - val_loss: 0.5187\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 414us/step - loss: 0.5389 - val_loss: 0.5182\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 416us/step - loss: 0.5375 - val_loss: 0.5164\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 412us/step - loss: 0.5362 - val_loss: 0.5161\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 417us/step - loss: 0.5352 - val_loss: 0.5150\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 409us/step - loss: 0.5343 - val_loss: 0.5145\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 417us/step - loss: 0.5333 - val_loss: 0.5138\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 412us/step - loss: 0.5324 - val_loss: 0.5145\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 413us/step - loss: 0.5316 - val_loss: 0.5134\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 412us/step - loss: 0.5311 - val_loss: 0.5128\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 407us/step - loss: 0.5304 - val_loss: 0.5126\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 411us/step - loss: 0.5298 - val_loss: 0.5122\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 412us/step - loss: 0.5293 - val_loss: 0.5119\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 411us/step - loss: 0.5287 - val_loss: 0.5119\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 413us/step - loss: 0.5284 - val_loss: 0.5127\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 417us/step - loss: 0.5279 - val_loss: 0.5125\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 783us/step - loss: 0.5277 - val_loss: 0.5113\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 410us/step - loss: 0.5273 - val_loss: 0.5119\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 423us/step - loss: 0.5269 - val_loss: 0.5103\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 410us/step - loss: 0.5267 - val_loss: 0.5105\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 410us/step - loss: 0.5265 - val_loss: 0.5113\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 414us/step - loss: 0.5263 - val_loss: 0.5106\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 413us/step - loss: 0.5259 - val_loss: 0.5124\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 413us/step - loss: 0.5258 - val_loss: 0.5110\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 413us/step - loss: 0.5257 - val_loss: 0.5112\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 413us/step - loss: 0.5254 - val_loss: 0.5118\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 413us/step - loss: 0.5254 - val_loss: 0.5106\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 420us/step - loss: 0.5252 - val_loss: 0.5104\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5251 - val_loss: 0.5111\n",
      "121/121 [==============================] - 0s 276us/step - loss: 0.5187\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 549us/step - loss: 4.4357 - val_loss: 1.9598\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 415us/step - loss: 1.4657 - val_loss: 0.9316\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 419us/step - loss: 0.8256 - val_loss: 0.6709\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 415us/step - loss: 0.6586 - val_loss: 0.5974\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 415us/step - loss: 0.6091 - val_loss: 0.5717\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 416us/step - loss: 0.5917 - val_loss: 0.5635\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 600us/step - loss: 0.5835 - val_loss: 0.5593\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 416us/step - loss: 0.5779 - val_loss: 0.5528\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 417us/step - loss: 0.5735 - val_loss: 0.5522\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 415us/step - loss: 0.5698 - val_loss: 0.5486\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 412us/step - loss: 0.5661 - val_loss: 0.5452\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 414us/step - loss: 0.5631 - val_loss: 0.5414\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 414us/step - loss: 0.5602 - val_loss: 0.5422\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 413us/step - loss: 0.5576 - val_loss: 0.5377\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 418us/step - loss: 0.5551 - val_loss: 0.5354\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 426us/step - loss: 0.5529 - val_loss: 0.5365\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 416us/step - loss: 0.5508 - val_loss: 0.5318\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 424us/step - loss: 0.5492 - val_loss: 0.5329\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 416us/step - loss: 0.5474 - val_loss: 0.5338\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 416us/step - loss: 0.5457 - val_loss: 0.5301\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 416us/step - loss: 0.5445 - val_loss: 0.5285\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 414us/step - loss: 0.5431 - val_loss: 0.5272\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 439us/step - loss: 0.5417 - val_loss: 0.5312\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 421us/step - loss: 0.5406 - val_loss: 0.5266\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 412us/step - loss: 0.5399 - val_loss: 0.5283\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 417us/step - loss: 0.5390 - val_loss: 0.5258\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 428us/step - loss: 0.5381 - val_loss: 0.5289\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 423us/step - loss: 0.5374 - val_loss: 0.5273\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 559us/step - loss: 0.5365 - val_loss: 0.5252\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 430us/step - loss: 0.5360 - val_loss: 0.5243\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 429us/step - loss: 0.5352 - val_loss: 0.5275\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 414us/step - loss: 0.5349 - val_loss: 0.5265\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 437us/step - loss: 0.5343 - val_loss: 0.5269\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 464us/step - loss: 0.5338 - val_loss: 0.5259\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 540us/step - loss: 0.5335 - val_loss: 0.5269\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 420us/step - loss: 0.5330 - val_loss: 0.5245\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 428us/step - loss: 0.5328 - val_loss: 0.5260\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 427us/step - loss: 0.5323 - val_loss: 0.5230\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 420us/step - loss: 0.5321 - val_loss: 0.5236\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 419us/step - loss: 0.5318 - val_loss: 0.5256\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 504us/step - loss: 0.5313 - val_loss: 0.5232\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 418us/step - loss: 0.5313 - val_loss: 0.5213\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 423us/step - loss: 0.5313 - val_loss: 0.5241\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 419us/step - loss: 0.5308 - val_loss: 0.5266\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 439us/step - loss: 0.5308 - val_loss: 0.5293\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 427us/step - loss: 0.5306 - val_loss: 0.5284\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 419us/step - loss: 0.5302 - val_loss: 0.5240\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 411us/step - loss: 0.5301 - val_loss: 0.5242\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 433us/step - loss: 0.5303 - val_loss: 0.5236\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 414us/step - loss: 0.5300 - val_loss: 0.5266\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 418us/step - loss: 0.5299 - val_loss: 0.5278\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 417us/step - loss: 0.5298 - val_loss: 0.5283\n",
      "121/121 [==============================] - 0s 290us/step - loss: 0.5080\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 647us/step - loss: 3.0041 - val_loss: 1.2822\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 417us/step - loss: 0.9383 - val_loss: 0.7813\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 422us/step - loss: 0.7254 - val_loss: 0.7018\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 425us/step - loss: 0.6763 - val_loss: 0.6596\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 425us/step - loss: 0.6488 - val_loss: 0.6349\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 415us/step - loss: 0.6252 - val_loss: 0.6102\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 715us/step - loss: 0.6083 - val_loss: 0.5961\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 436us/step - loss: 0.5917 - val_loss: 0.5805\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 453us/step - loss: 0.5794 - val_loss: 0.5690\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 422us/step - loss: 0.5672 - val_loss: 0.5724\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 428us/step - loss: 0.5591 - val_loss: 0.5528\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 424us/step - loss: 0.5510 - val_loss: 0.5452\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 425us/step - loss: 0.5443 - val_loss: 0.5519\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 530us/step - loss: 0.5376 - val_loss: 0.5347\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 427us/step - loss: 0.5353 - val_loss: 0.5330\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 429us/step - loss: 0.5303 - val_loss: 0.5364\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 418us/step - loss: 0.5273 - val_loss: 0.5444\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 424us/step - loss: 0.5250 - val_loss: 0.5296\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 418us/step - loss: 0.5217 - val_loss: 0.5237\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 425us/step - loss: 0.5203 - val_loss: 0.5400\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 419us/step - loss: 0.5188 - val_loss: 0.5339\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 418us/step - loss: 0.5170 - val_loss: 0.5204\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 416us/step - loss: 0.5160 - val_loss: 0.5367\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 412us/step - loss: 0.5150 - val_loss: 0.5389\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 412us/step - loss: 0.5145 - val_loss: 0.5257\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.5126 - val_loss: 0.5198\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 421us/step - loss: 0.5118 - val_loss: 0.5146\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 463us/step - loss: 0.5129 - val_loss: 0.5184\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 471us/step - loss: 0.5115 - val_loss: 0.5352\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.5115 - val_loss: 0.5299\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 589us/step - loss: 0.5106 - val_loss: 0.5304\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 438us/step - loss: 0.5094 - val_loss: 0.5146\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 406us/step - loss: 0.5109 - val_loss: 0.5257\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 422us/step - loss: 0.5095 - val_loss: 0.5327\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 421us/step - loss: 0.5095 - val_loss: 0.5183\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 412us/step - loss: 0.5096 - val_loss: 0.5151\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 420us/step - loss: 0.5102 - val_loss: 0.5304\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 421us/step - loss: 0.5089 - val_loss: 0.5377\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 412us/step - loss: 0.5082 - val_loss: 0.5180\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 417us/step - loss: 0.5091 - val_loss: 0.5188\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 419us/step - loss: 0.5094 - val_loss: 0.5191\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.5095 - val_loss: 0.5322\n",
      "121/121 [==============================] - 0s 276us/step - loss: 0.5488\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 575us/step - loss: 3.2869 - val_loss: 1.1074\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 415us/step - loss: 0.8086 - val_loss: 0.6486\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 495us/step - loss: 0.6357 - val_loss: 0.5971\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 593us/step - loss: 0.6069 - val_loss: 0.5761\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 466us/step - loss: 0.5921 - val_loss: 0.5648\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 435us/step - loss: 0.5812 - val_loss: 0.5533\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 417us/step - loss: 0.5717 - val_loss: 0.5439\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 421us/step - loss: 0.5640 - val_loss: 0.5384\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 558us/step - loss: 0.5578 - val_loss: 0.5322\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 435us/step - loss: 0.5523 - val_loss: 0.5276\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 415us/step - loss: 0.5477 - val_loss: 0.5243\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 422us/step - loss: 0.5441 - val_loss: 0.5222\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 421us/step - loss: 0.5409 - val_loss: 0.5191\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 417us/step - loss: 0.5383 - val_loss: 0.5165\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 420us/step - loss: 0.5357 - val_loss: 0.5154\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 425us/step - loss: 0.5345 - val_loss: 0.5142\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 933us/step - loss: 0.5324 - val_loss: 0.5125\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 699us/step - loss: 0.5307 - val_loss: 0.5150\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 720us/step - loss: 0.5305 - val_loss: 0.5138\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 988us/step - loss: 0.5290 - val_loss: 0.5167\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 621us/step - loss: 0.5282 - val_loss: 0.5198\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 423us/step - loss: 0.5284 - val_loss: 0.5173\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 423us/step - loss: 0.5273 - val_loss: 0.5102\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 419us/step - loss: 0.5262 - val_loss: 0.5143\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 425us/step - loss: 0.5265 - val_loss: 0.5119\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 421us/step - loss: 0.5266 - val_loss: 0.5116\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 0.5261 - val_loss: 0.5091\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 460us/step - loss: 0.5260 - val_loss: 0.5121\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 421us/step - loss: 0.5258 - val_loss: 0.5081\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 417us/step - loss: 0.5254 - val_loss: 0.5147\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 436us/step - loss: 0.5254 - val_loss: 0.5090\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 424us/step - loss: 0.5250 - val_loss: 0.5149\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 425us/step - loss: 0.5251 - val_loss: 0.5119\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 431us/step - loss: 0.5246 - val_loss: 0.5151\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 442us/step - loss: 0.5247 - val_loss: 0.5094\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 460us/step - loss: 0.5252 - val_loss: 0.5101\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 438us/step - loss: 0.5245 - val_loss: 0.5085\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 530us/step - loss: 0.5250 - val_loss: 0.5119\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 538us/step - loss: 0.5243 - val_loss: 0.5080\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 420us/step - loss: 0.5250 - val_loss: 0.5101\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 419us/step - loss: 0.5252 - val_loss: 0.5103\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 417us/step - loss: 0.5249 - val_loss: 0.5110\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 419us/step - loss: 0.5249 - val_loss: 0.5133\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 417us/step - loss: 0.5244 - val_loss: 0.5137\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 437us/step - loss: 0.5246 - val_loss: 0.5108\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 433us/step - loss: 0.5244 - val_loss: 0.5089\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 418us/step - loss: 0.5235 - val_loss: 0.5211\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 422us/step - loss: 0.5252 - val_loss: 0.5154\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 419us/step - loss: 0.5247 - val_loss: 0.5134\n",
      "121/121 [==============================] - 0s 269us/step - loss: 0.5158\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 565us/step - loss: 3.0376 - val_loss: 1.1891\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 443us/step - loss: 0.9027 - val_loss: 0.7365\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 415us/step - loss: 0.7054 - val_loss: 0.6604\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 421us/step - loss: 0.6620 - val_loss: 0.6266\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.6382 - val_loss: 0.6035\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 421us/step - loss: 0.6193 - val_loss: 0.5862\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 432us/step - loss: 0.6043 - val_loss: 0.5702\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 425us/step - loss: 0.5926 - val_loss: 0.5622\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 463us/step - loss: 0.5810 - val_loss: 0.5496\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 0.5732 - val_loss: 0.5434\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 643us/step - loss: 0.5647 - val_loss: 0.5352\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 863us/step - loss: 0.5596 - val_loss: 0.5308\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 498us/step - loss: 0.5549 - val_loss: 0.5284\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 428us/step - loss: 0.5506 - val_loss: 0.5305\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 419us/step - loss: 0.5455 - val_loss: 0.5205\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 416us/step - loss: 0.5446 - val_loss: 0.5241\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 506us/step - loss: 0.5412 - val_loss: 0.5207\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 494us/step - loss: 0.5397 - val_loss: 0.5249\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 424us/step - loss: 0.5379 - val_loss: 0.5275\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 432us/step - loss: 0.5363 - val_loss: 0.5207\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 424us/step - loss: 0.5349 - val_loss: 0.5250\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 569us/step - loss: 0.5339 - val_loss: 0.5221\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 983us/step - loss: 0.5336 - val_loss: 0.5191\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 981us/step - loss: 0.5329 - val_loss: 0.5174\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 701us/step - loss: 0.5323 - val_loss: 0.5242\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 422us/step - loss: 0.5315 - val_loss: 0.5201\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 443us/step - loss: 0.5312 - val_loss: 0.5197\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 419us/step - loss: 0.5312 - val_loss: 0.5263\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 422us/step - loss: 0.5308 - val_loss: 0.5235\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 418us/step - loss: 0.5300 - val_loss: 0.5219\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 416us/step - loss: 0.5304 - val_loss: 0.5206\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 414us/step - loss: 0.5300 - val_loss: 0.5233\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 415us/step - loss: 0.5301 - val_loss: 0.5244\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 449us/step - loss: 0.5298 - val_loss: 0.5228\n",
      "121/121 [==============================] - 0s 283us/step - loss: 0.5052\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 635us/step - loss: 0.8687 - val_loss: 0.5416\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 476us/step - loss: 0.5204 - val_loss: 0.4897\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 470us/step - loss: 0.4715 - val_loss: 0.4606\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 717us/step - loss: 0.4592 - val_loss: 0.4638\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 558us/step - loss: 0.4373 - val_loss: 0.4252\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 708us/step - loss: 0.4223 - val_loss: 0.3966\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 513us/step - loss: 0.4085 - val_loss: 0.4084\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 476us/step - loss: 0.4065 - val_loss: 0.4069\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 468us/step - loss: 0.3963 - val_loss: 0.4191\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 477us/step - loss: 0.4492 - val_loss: 0.3992\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 470us/step - loss: 0.3962 - val_loss: 0.3778\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 0.3809 - val_loss: 0.3669\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 0.3660 - val_loss: 0.3624\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 493us/step - loss: 0.3629 - val_loss: 0.3436\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 471us/step - loss: 0.3570 - val_loss: 0.3480\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 469us/step - loss: 0.3494 - val_loss: 0.3939\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 472us/step - loss: 0.3483 - val_loss: 0.3332\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 468us/step - loss: 0.3447 - val_loss: 0.3305\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 469us/step - loss: 0.3389 - val_loss: 0.3519\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 472us/step - loss: 0.3388 - val_loss: 0.3295\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 501us/step - loss: 0.3364 - val_loss: 0.3279\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 524us/step - loss: 0.3321 - val_loss: 0.3294\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 470us/step - loss: 0.3315 - val_loss: 0.3228\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 601us/step - loss: 0.3298 - val_loss: 0.3234\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3284 - val_loss: 0.3261\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 595us/step - loss: 0.3254 - val_loss: 0.3319\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 513us/step - loss: 0.3248 - val_loss: 0.3326\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 463us/step - loss: 0.3237 - val_loss: 0.3153\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 651us/step - loss: 0.3216 - val_loss: 0.3279\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 537us/step - loss: 0.3202 - val_loss: 0.3186\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 598us/step - loss: 0.3221 - val_loss: 0.3286\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 514us/step - loss: 0.3200 - val_loss: 0.3141\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 644us/step - loss: 0.3167 - val_loss: 0.3233\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.3170 - val_loss: 0.3250\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 468us/step - loss: 0.3158 - val_loss: 0.3223\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 477us/step - loss: 0.3164 - val_loss: 0.3098\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 450us/step - loss: 0.3124 - val_loss: 0.3320\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 466us/step - loss: 0.3125 - val_loss: 0.3203\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 0.3126 - val_loss: 0.3086\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 490us/step - loss: 0.3133 - val_loss: 0.3062\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 469us/step - loss: 0.3114 - val_loss: 0.3170\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 469us/step - loss: 0.3103 - val_loss: 0.3281\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 473us/step - loss: 0.3120 - val_loss: 0.3187\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 468us/step - loss: 0.3093 - val_loss: 0.3144\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 473us/step - loss: 0.3113 - val_loss: 0.3333\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 490us/step - loss: 0.3117 - val_loss: 0.3319\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 462us/step - loss: 0.3092 - val_loss: 0.3143\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 473us/step - loss: 0.3092 - val_loss: 0.3024\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 471us/step - loss: 0.3095 - val_loss: 0.3072\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 469us/step - loss: 0.3070 - val_loss: 0.3088\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 470us/step - loss: 0.3054 - val_loss: 0.2999\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 497us/step - loss: 0.3050 - val_loss: 0.3004\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 472us/step - loss: 0.3063 - val_loss: 0.3339\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 0.3042 - val_loss: 0.2984\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 478us/step - loss: 0.3041 - val_loss: 0.3049\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 475us/step - loss: 0.3018 - val_loss: 0.3261\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 475us/step - loss: 0.3017 - val_loss: 0.3439\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 506us/step - loss: 0.3023 - val_loss: 0.3057\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 468us/step - loss: 0.3022 - val_loss: 0.3111\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 478us/step - loss: 0.3013 - val_loss: 0.3043\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 476us/step - loss: 0.3006 - val_loss: 0.3061\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 471us/step - loss: 0.3013 - val_loss: 0.3111\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 0.2977 - val_loss: 0.3043\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 511us/step - loss: 0.2978 - val_loss: 0.3130\n",
      "121/121 [==============================] - 0s 288us/step - loss: 0.3400\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 641us/step - loss: 0.8177 - val_loss: 0.5018\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 471us/step - loss: 0.4972 - val_loss: 0.4554\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 556us/step - loss: 0.4470 - val_loss: 0.4232\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 503us/step - loss: 0.4303 - val_loss: 0.4085\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 472us/step - loss: 0.4201 - val_loss: 0.4010\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 511us/step - loss: 0.4113 - val_loss: 0.3992\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 478us/step - loss: 0.4037 - val_loss: 0.3996\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 476us/step - loss: 0.4012 - val_loss: 0.3885\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 513us/step - loss: 0.3946 - val_loss: 0.3828\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 0.3909 - val_loss: 0.3857\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 595us/step - loss: 0.3863 - val_loss: 0.3805\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 507us/step - loss: 0.3835 - val_loss: 0.3744\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 470us/step - loss: 0.3814 - val_loss: 0.3688\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 522us/step - loss: 0.3779 - val_loss: 0.3705\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 555us/step - loss: 0.3741 - val_loss: 0.3964\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 549us/step - loss: 0.3728 - val_loss: 0.3809\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 0.3707 - val_loss: 0.3686\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 497us/step - loss: 0.3678 - val_loss: 0.3585\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 467us/step - loss: 0.3658 - val_loss: 0.3556\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 489us/step - loss: 0.3618 - val_loss: 0.3682\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 486us/step - loss: 0.3592 - val_loss: 0.3533\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 508us/step - loss: 0.3596 - val_loss: 0.3516\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 466us/step - loss: 0.3573 - val_loss: 0.3483\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 485us/step - loss: 0.3557 - val_loss: 0.3480\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 0.3504 - val_loss: 0.3408\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 495us/step - loss: 0.3503 - val_loss: 0.3385\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 475us/step - loss: 0.3468 - val_loss: 0.3410\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 472us/step - loss: 0.3460 - val_loss: 0.3372\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 467us/step - loss: 0.3442 - val_loss: 0.3389\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.3416 - val_loss: 0.3397\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 473us/step - loss: 0.3418 - val_loss: 0.3319\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 469us/step - loss: 0.3405 - val_loss: 0.3341\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 472us/step - loss: 0.3381 - val_loss: 0.3342\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 466us/step - loss: 0.3368 - val_loss: 0.3412\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 471us/step - loss: 0.3367 - val_loss: 0.3285\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 525us/step - loss: 0.3357 - val_loss: 0.3308\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 861us/step - loss: 0.3347 - val_loss: 0.3319\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 568us/step - loss: 0.3343 - val_loss: 0.3274\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 580us/step - loss: 0.3322 - val_loss: 0.3351\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3329 - val_loss: 0.3369\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 535us/step - loss: 0.3290 - val_loss: 0.3311\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 688us/step - loss: 0.3272 - val_loss: 0.3372\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 553us/step - loss: 0.3280 - val_loss: 0.3321\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 454us/step - loss: 0.3273 - val_loss: 0.3180\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.3262 - val_loss: 0.3347\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 449us/step - loss: 0.3267 - val_loss: 0.3368\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 450us/step - loss: 0.3251 - val_loss: 0.3206\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 717us/step - loss: 0.3258 - val_loss: 0.3161\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 506us/step - loss: 0.3242 - val_loss: 0.3262\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 517us/step - loss: 0.3233 - val_loss: 0.3238\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 487us/step - loss: 0.3230 - val_loss: 0.3201\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 0.3207 - val_loss: 0.3162\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 472us/step - loss: 0.3208 - val_loss: 0.3205\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 504us/step - loss: 0.3225 - val_loss: 0.3334\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 451us/step - loss: 0.3168 - val_loss: 0.3140\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 678us/step - loss: 0.3192 - val_loss: 0.3146\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 503us/step - loss: 0.3177 - val_loss: 0.3357\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.3180 - val_loss: 0.3120\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 474us/step - loss: 0.3146 - val_loss: 0.3190\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 452us/step - loss: 0.3163 - val_loss: 0.3195\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 452us/step - loss: 0.3171 - val_loss: 0.3200\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 499us/step - loss: 0.3157 - val_loss: 0.3139\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 547us/step - loss: 0.3148 - val_loss: 0.3843\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 570us/step - loss: 0.3159 - val_loss: 0.3309\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 512us/step - loss: 0.3156 - val_loss: 0.3176\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 507us/step - loss: 0.3126 - val_loss: 0.3103\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 459us/step - loss: 0.3139 - val_loss: 0.3192\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 0.3108 - val_loss: 0.3184\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 469us/step - loss: 0.3149 - val_loss: 0.3199\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 512us/step - loss: 0.3106 - val_loss: 0.3296\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 493us/step - loss: 0.3102 - val_loss: 0.3140\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 507us/step - loss: 0.3090 - val_loss: 0.3092\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 492us/step - loss: 0.3103 - val_loss: 0.3169\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 495us/step - loss: 0.3099 - val_loss: 0.3121\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 498us/step - loss: 0.3120 - val_loss: 0.3236\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 500us/step - loss: 0.3081 - val_loss: 0.3067\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 499us/step - loss: 0.3093 - val_loss: 0.3120\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 494us/step - loss: 0.3095 - val_loss: 0.3054\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 515us/step - loss: 0.3088 - val_loss: 0.3255\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 492us/step - loss: 0.3086 - val_loss: 0.3028\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 491us/step - loss: 0.3083 - val_loss: 0.3042\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 500us/step - loss: 0.3053 - val_loss: 0.3054\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 501us/step - loss: 0.3047 - val_loss: 0.3102\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 496us/step - loss: 0.3061 - val_loss: 0.3062\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 496us/step - loss: 0.3070 - val_loss: 0.3099\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 495us/step - loss: 0.3078 - val_loss: 0.3044\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 453us/step - loss: 0.3063 - val_loss: 0.3115\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 454us/step - loss: 0.3030 - val_loss: 0.3155\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 0.3049 - val_loss: 0.3196\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 450us/step - loss: 0.3046 - val_loss: 0.3006\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 452us/step - loss: 0.3020 - val_loss: 0.3143\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 443us/step - loss: 0.3022 - val_loss: 0.3189\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.3016 - val_loss: 0.3037\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 466us/step - loss: 0.3035 - val_loss: 0.2995\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 441us/step - loss: 0.3013 - val_loss: 0.3044\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.3016 - val_loss: 0.3100\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 464us/step - loss: 0.3026 - val_loss: 0.3101\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 507us/step - loss: 0.3011 - val_loss: 0.3017\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 533us/step - loss: 0.3001 - val_loss: 0.2983\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 497us/step - loss: 0.3000 - val_loss: 0.3017\n",
      "121/121 [==============================] - 0s 312us/step - loss: 0.3246\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 698us/step - loss: 0.9585 - val_loss: 0.6794\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 500us/step - loss: 0.7163 - val_loss: 0.6409\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 511us/step - loss: 0.6572 - val_loss: 0.5539\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 521us/step - loss: 0.5464 - val_loss: 0.4812\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 509us/step - loss: 0.4854 - val_loss: 0.4498\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 505us/step - loss: 0.4575 - val_loss: 0.4317\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 0.4411 - val_loss: 0.4103\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 438us/step - loss: 0.4277 - val_loss: 0.4064\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 463us/step - loss: 0.4189 - val_loss: 0.3920\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.4091 - val_loss: 0.3907\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 442us/step - loss: 0.4008 - val_loss: 0.3686\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 0.3912 - val_loss: 0.3644\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 435us/step - loss: 0.3862 - val_loss: 0.3590\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 457us/step - loss: 0.3818 - val_loss: 0.3520\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 441us/step - loss: 0.3775 - val_loss: 0.3557\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.3711 - val_loss: 0.3525\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.3675 - val_loss: 0.3519\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 459us/step - loss: 0.3647 - val_loss: 0.3477\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 443us/step - loss: 0.3601 - val_loss: 0.3665\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 440us/step - loss: 0.3559 - val_loss: 0.3377\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 467us/step - loss: 0.3538 - val_loss: 0.3354\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 505us/step - loss: 0.3521 - val_loss: 0.3285\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 545us/step - loss: 0.3491 - val_loss: 0.3430\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 507us/step - loss: 0.3469 - val_loss: 0.3317\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 510us/step - loss: 0.3447 - val_loss: 0.3332\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 503us/step - loss: 0.3407 - val_loss: 0.3453\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 538us/step - loss: 0.3417 - val_loss: 0.3295\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 510us/step - loss: 0.3387 - val_loss: 0.3382\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 457us/step - loss: 0.3374 - val_loss: 0.3287\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 477us/step - loss: 0.3365 - val_loss: 0.3215\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 462us/step - loss: 0.3347 - val_loss: 0.3295\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 0.3359 - val_loss: 0.3231\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 436us/step - loss: 0.3339 - val_loss: 0.3351\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 441us/step - loss: 0.3306 - val_loss: 0.3259\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 460us/step - loss: 0.3304 - val_loss: 0.3213\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 544us/step - loss: 0.3299 - val_loss: 0.3276\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 513us/step - loss: 0.3296 - val_loss: 0.3320\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 512us/step - loss: 0.3289 - val_loss: 0.3301\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 491us/step - loss: 0.3278 - val_loss: 0.3248\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 493us/step - loss: 0.3268 - val_loss: 0.3199\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 532us/step - loss: 0.3280 - val_loss: 0.3186\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 490us/step - loss: 0.3253 - val_loss: 0.3416\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 549us/step - loss: 0.3230 - val_loss: 0.3305\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 507us/step - loss: 0.3251 - val_loss: 0.3306\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 504us/step - loss: 0.3233 - val_loss: 0.3315\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 526us/step - loss: 0.3243 - val_loss: 0.3326\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 463us/step - loss: 0.3231 - val_loss: 0.3273\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 440us/step - loss: 0.3247 - val_loss: 0.3192\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 452us/step - loss: 0.3224 - val_loss: 0.3217\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 490us/step - loss: 0.3225 - val_loss: 0.3136\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 507us/step - loss: 0.3207 - val_loss: 0.3200\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 526us/step - loss: 0.3214 - val_loss: 0.3308\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 464us/step - loss: 0.3220 - val_loss: 0.3405\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 598us/step - loss: 0.3200 - val_loss: 0.3180\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 450us/step - loss: 0.3201 - val_loss: 0.3239\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.3213 - val_loss: 0.3273\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.3192 - val_loss: 0.3348\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 456us/step - loss: 0.3199 - val_loss: 0.3197\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.3197 - val_loss: 0.3169\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 0.3181 - val_loss: 0.3192\n",
      "121/121 [==============================] - 0s 268us/step - loss: 0.3136\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 666us/step - loss: 3.0049 - val_loss: 1.7319\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 512us/step - loss: 1.2840 - val_loss: 1.0972\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 580us/step - loss: 0.9742 - val_loss: 0.9045\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 552us/step - loss: 0.8374 - val_loss: 0.7999\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 549us/step - loss: 0.7618 - val_loss: 0.7405\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 533us/step - loss: 0.7163 - val_loss: 0.7010\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 542us/step - loss: 0.6857 - val_loss: 0.6752\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 575us/step - loss: 0.6635 - val_loss: 0.6539\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 555us/step - loss: 0.6449 - val_loss: 0.6356\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 516us/step - loss: 0.6299 - val_loss: 0.6221\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 516us/step - loss: 0.6166 - val_loss: 0.6094\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 539us/step - loss: 0.6047 - val_loss: 0.5980\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 561us/step - loss: 0.5941 - val_loss: 0.5865\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 548us/step - loss: 0.5843 - val_loss: 0.5775\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 562us/step - loss: 0.5755 - val_loss: 0.5684\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 557us/step - loss: 0.5674 - val_loss: 0.5603\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 545us/step - loss: 0.5597 - val_loss: 0.5530\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 511us/step - loss: 0.5526 - val_loss: 0.5454\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 513us/step - loss: 0.5458 - val_loss: 0.5386\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 511us/step - loss: 0.5397 - val_loss: 0.5326\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 490us/step - loss: 0.5336 - val_loss: 0.5263\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 489us/step - loss: 0.5281 - val_loss: 0.5213\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 490us/step - loss: 0.5226 - val_loss: 0.5150\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 489us/step - loss: 0.5177 - val_loss: 0.5109\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 498us/step - loss: 0.5128 - val_loss: 0.5061\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 492us/step - loss: 0.5084 - val_loss: 0.5006\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 492us/step - loss: 0.5040 - val_loss: 0.4962\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 550us/step - loss: 0.4999 - val_loss: 0.4920\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 614us/step - loss: 0.4959 - val_loss: 0.4885\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 555us/step - loss: 0.4919 - val_loss: 0.4848\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 510us/step - loss: 0.4885 - val_loss: 0.4807\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 676us/step - loss: 0.4850 - val_loss: 0.4773\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 528us/step - loss: 0.4815 - val_loss: 0.4737\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 534us/step - loss: 0.4785 - val_loss: 0.4710\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 518us/step - loss: 0.4753 - val_loss: 0.4677\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 536us/step - loss: 0.4723 - val_loss: 0.4647\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 512us/step - loss: 0.4695 - val_loss: 0.4622\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 516us/step - loss: 0.4667 - val_loss: 0.4586\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 516us/step - loss: 0.4641 - val_loss: 0.4565\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 515us/step - loss: 0.4615 - val_loss: 0.4540\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 516us/step - loss: 0.4590 - val_loss: 0.4517\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 532us/step - loss: 0.4565 - val_loss: 0.4490\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 517us/step - loss: 0.4543 - val_loss: 0.4466\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 517us/step - loss: 0.4519 - val_loss: 0.4444\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 530us/step - loss: 0.4498 - val_loss: 0.4426\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 522us/step - loss: 0.4476 - val_loss: 0.4405\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 600us/step - loss: 0.4456 - val_loss: 0.4386\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 686us/step - loss: 0.4435 - val_loss: 0.4364\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 585us/step - loss: 0.4415 - val_loss: 0.4347\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 876us/step - loss: 0.4393 - val_loss: 0.4340\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 588us/step - loss: 0.4378 - val_loss: 0.4313\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 512us/step - loss: 0.4359 - val_loss: 0.4288\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 525us/step - loss: 0.4342 - val_loss: 0.4277\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 661us/step - loss: 0.4325 - val_loss: 0.4259\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 508us/step - loss: 0.4307 - val_loss: 0.4241\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 514us/step - loss: 0.4291 - val_loss: 0.4229\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 508us/step - loss: 0.4274 - val_loss: 0.4220\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 532us/step - loss: 0.4259 - val_loss: 0.4192\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 500us/step - loss: 0.4243 - val_loss: 0.4186\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 506us/step - loss: 0.4226 - val_loss: 0.4163\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 506us/step - loss: 0.4212 - val_loss: 0.4156\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 524us/step - loss: 0.4197 - val_loss: 0.4136\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 504us/step - loss: 0.4182 - val_loss: 0.4123\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 509us/step - loss: 0.4168 - val_loss: 0.4107\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 506us/step - loss: 0.4153 - val_loss: 0.4102\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 530us/step - loss: 0.4139 - val_loss: 0.4087\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 518us/step - loss: 0.4126 - val_loss: 0.4074\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 516us/step - loss: 0.4113 - val_loss: 0.4054\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 564us/step - loss: 0.4099 - val_loss: 0.4037\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 932us/step - loss: 0.4086 - val_loss: 0.4032\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 587us/step - loss: 0.4073 - val_loss: 0.4021\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 508us/step - loss: 0.4058 - val_loss: 0.4000\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 510us/step - loss: 0.4047 - val_loss: 0.3996\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 528us/step - loss: 0.4035 - val_loss: 0.3977\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 507us/step - loss: 0.4023 - val_loss: 0.3968\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 502us/step - loss: 0.4011 - val_loss: 0.3961\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 507us/step - loss: 0.3999 - val_loss: 0.3945\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 529us/step - loss: 0.3988 - val_loss: 0.3936\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 508us/step - loss: 0.3977 - val_loss: 0.3934\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 506us/step - loss: 0.3965 - val_loss: 0.3912\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 520us/step - loss: 0.3954 - val_loss: 0.3901\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 536us/step - loss: 0.3943 - val_loss: 0.3885\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 575us/step - loss: 0.3931 - val_loss: 0.3895\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 564us/step - loss: 0.3921 - val_loss: 0.3870\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 587us/step - loss: 0.3911 - val_loss: 0.3860\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 531us/step - loss: 0.3900 - val_loss: 0.3849\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 506us/step - loss: 0.3889 - val_loss: 0.3853\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 510us/step - loss: 0.3880 - val_loss: 0.3827\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 511us/step - loss: 0.3870 - val_loss: 0.3830\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 533us/step - loss: 0.3861 - val_loss: 0.3813\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 509us/step - loss: 0.3852 - val_loss: 0.3815\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 507us/step - loss: 0.3842 - val_loss: 0.3794\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 505us/step - loss: 0.3833 - val_loss: 0.3785\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 534us/step - loss: 0.3825 - val_loss: 0.3778\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 505us/step - loss: 0.3816 - val_loss: 0.3775\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 509us/step - loss: 0.3807 - val_loss: 0.3768\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 512us/step - loss: 0.3798 - val_loss: 0.3764\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 536us/step - loss: 0.3789 - val_loss: 0.3760\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 556us/step - loss: 0.3782 - val_loss: 0.3736\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 567us/step - loss: 0.3772 - val_loss: 0.3730\n",
      "121/121 [==============================] - 0s 566us/step - loss: 0.4200\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 769us/step - loss: 3.2896 - val_loss: 1.7982\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 616us/step - loss: 1.4335 - val_loss: 1.1106\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 504us/step - loss: 1.0137 - val_loss: 0.9195\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 509us/step - loss: 0.8614 - val_loss: 0.8279\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 508us/step - loss: 0.7913 - val_loss: 0.7788\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 527us/step - loss: 0.7540 - val_loss: 0.7474\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 508us/step - loss: 0.7296 - val_loss: 0.7247\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 506us/step - loss: 0.7106 - val_loss: 0.7055\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 507us/step - loss: 0.6940 - val_loss: 0.6894\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 525us/step - loss: 0.6800 - val_loss: 0.6744\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 517us/step - loss: 0.6669 - val_loss: 0.6611\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 507us/step - loss: 0.6546 - val_loss: 0.6486\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 538us/step - loss: 0.6437 - val_loss: 0.6372\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 578us/step - loss: 0.6331 - val_loss: 0.6261\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 537us/step - loss: 0.6232 - val_loss: 0.6160\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 513us/step - loss: 0.6137 - val_loss: 0.6062\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 644us/step - loss: 0.6050 - val_loss: 0.5973\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 505us/step - loss: 0.5967 - val_loss: 0.5884\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 507us/step - loss: 0.5886 - val_loss: 0.5799\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 514us/step - loss: 0.5811 - val_loss: 0.5722\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 528us/step - loss: 0.5739 - val_loss: 0.5645\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 507us/step - loss: 0.5667 - val_loss: 0.5570\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 633us/step - loss: 0.5603 - val_loss: 0.5501\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 522us/step - loss: 0.5537 - val_loss: 0.5433\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 519us/step - loss: 0.5476 - val_loss: 0.5369\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 513us/step - loss: 0.5416 - val_loss: 0.5305\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 504us/step - loss: 0.5359 - val_loss: 0.5249\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 557us/step - loss: 0.5305 - val_loss: 0.5191\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 744us/step - loss: 0.5252 - val_loss: 0.5136\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 534us/step - loss: 0.5202 - val_loss: 0.5082\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 566us/step - loss: 0.5153 - val_loss: 0.5030\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 548us/step - loss: 0.5106 - val_loss: 0.4983\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 528us/step - loss: 0.5063 - val_loss: 0.4934\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 506us/step - loss: 0.5020 - val_loss: 0.4891\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 613us/step - loss: 0.4980 - val_loss: 0.4847\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 525us/step - loss: 0.4941 - val_loss: 0.4805\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 506us/step - loss: 0.4903 - val_loss: 0.4764\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 505us/step - loss: 0.4865 - val_loss: 0.4728\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 504us/step - loss: 0.4831 - val_loss: 0.4687\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 533us/step - loss: 0.4797 - val_loss: 0.4650\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 646us/step - loss: 0.4765 - val_loss: 0.4617\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 503us/step - loss: 0.4730 - val_loss: 0.4587\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 528us/step - loss: 0.4702 - val_loss: 0.4557\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 503us/step - loss: 0.4673 - val_loss: 0.4526\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 503us/step - loss: 0.4646 - val_loss: 0.4494\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 509us/step - loss: 0.4617 - val_loss: 0.4465\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 628us/step - loss: 0.4590 - val_loss: 0.4435\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 543us/step - loss: 0.4565 - val_loss: 0.4409\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 586us/step - loss: 0.4540 - val_loss: 0.4382\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 563us/step - loss: 0.4517 - val_loss: 0.4359\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 510us/step - loss: 0.4494 - val_loss: 0.4338\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 510us/step - loss: 0.4471 - val_loss: 0.4313\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 557us/step - loss: 0.4450 - val_loss: 0.4289\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 626us/step - loss: 0.4429 - val_loss: 0.4267\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 507us/step - loss: 0.4407 - val_loss: 0.4245\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 531us/step - loss: 0.4387 - val_loss: 0.4227\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 502us/step - loss: 0.4369 - val_loss: 0.4206\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 509us/step - loss: 0.4349 - val_loss: 0.4187\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 523us/step - loss: 0.4331 - val_loss: 0.4172\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 609us/step - loss: 0.4314 - val_loss: 0.4151\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 503us/step - loss: 0.4296 - val_loss: 0.4135\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 516us/step - loss: 0.4278 - val_loss: 0.4118\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 507us/step - loss: 0.4263 - val_loss: 0.4102\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 517us/step - loss: 0.4247 - val_loss: 0.4083\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 529us/step - loss: 0.4230 - val_loss: 0.4067\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 624us/step - loss: 0.4215 - val_loss: 0.4054\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 491us/step - loss: 0.4199 - val_loss: 0.4041\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 629us/step - loss: 0.4183 - val_loss: 0.4027\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 513us/step - loss: 0.4167 - val_loss: 0.4013\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 491us/step - loss: 0.4156 - val_loss: 0.3994\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 491us/step - loss: 0.4141 - val_loss: 0.3984\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 594us/step - loss: 0.4127 - val_loss: 0.3968\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 507us/step - loss: 0.4113 - val_loss: 0.3961\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 493us/step - loss: 0.4100 - val_loss: 0.3944\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 492us/step - loss: 0.4088 - val_loss: 0.3934\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 507us/step - loss: 0.4076 - val_loss: 0.3923\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 493us/step - loss: 0.4063 - val_loss: 0.3910\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 494us/step - loss: 0.4052 - val_loss: 0.3905\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 506us/step - loss: 0.4041 - val_loss: 0.3894\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 503us/step - loss: 0.4029 - val_loss: 0.3883\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 581us/step - loss: 0.4017 - val_loss: 0.3878\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 610us/step - loss: 0.4007 - val_loss: 0.3860\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 502us/step - loss: 0.3994 - val_loss: 0.3855\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 493us/step - loss: 0.3986 - val_loss: 0.3841\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 512us/step - loss: 0.3974 - val_loss: 0.3830\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 494us/step - loss: 0.3965 - val_loss: 0.3827\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 496us/step - loss: 0.3954 - val_loss: 0.3815\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 509us/step - loss: 0.3945 - val_loss: 0.3808\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 512us/step - loss: 0.3936 - val_loss: 0.3798\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 495us/step - loss: 0.3927 - val_loss: 0.3793\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 494us/step - loss: 0.3916 - val_loss: 0.3785\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 537us/step - loss: 0.3909 - val_loss: 0.3777\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 538us/step - loss: 0.3900 - val_loss: 0.3770\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 541us/step - loss: 0.3890 - val_loss: 0.3766\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 644us/step - loss: 0.3882 - val_loss: 0.3754\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 556us/step - loss: 0.3872 - val_loss: 0.3745\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 555us/step - loss: 0.3862 - val_loss: 0.3743\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 583us/step - loss: 0.3856 - val_loss: 0.3733\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 541us/step - loss: 0.3849 - val_loss: 0.3726\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 546us/step - loss: 0.3842 - val_loss: 0.3723\n",
      "121/121 [==============================] - 0s 300us/step - loss: 0.3924\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 702us/step - loss: 3.1284 - val_loss: 1.8608\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 556us/step - loss: 1.4164 - val_loss: 1.1166\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 512us/step - loss: 1.0205 - val_loss: 0.8987\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 524us/step - loss: 0.8684 - val_loss: 0.7994\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 485us/step - loss: 0.7896 - val_loss: 0.7459\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 494us/step - loss: 0.7462 - val_loss: 0.7126\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 515us/step - loss: 0.7196 - val_loss: 0.6913\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 492us/step - loss: 0.7012 - val_loss: 0.6749\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 490us/step - loss: 0.6869 - val_loss: 0.6609\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 511us/step - loss: 0.6745 - val_loss: 0.6493\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 493us/step - loss: 0.6636 - val_loss: 0.6381\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 492us/step - loss: 0.6532 - val_loss: 0.6284\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 507us/step - loss: 0.6438 - val_loss: 0.6184\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 491us/step - loss: 0.6348 - val_loss: 0.6089\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 490us/step - loss: 0.6263 - val_loss: 0.6004\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 494us/step - loss: 0.6180 - val_loss: 0.5918\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 521us/step - loss: 0.6100 - val_loss: 0.5837\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 495us/step - loss: 0.6021 - val_loss: 0.5765\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 493us/step - loss: 0.5948 - val_loss: 0.5682\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 513us/step - loss: 0.5876 - val_loss: 0.5606\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 495us/step - loss: 0.5807 - val_loss: 0.5533\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 494us/step - loss: 0.5739 - val_loss: 0.5469\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 492us/step - loss: 0.5673 - val_loss: 0.5404\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 513us/step - loss: 0.5609 - val_loss: 0.5344\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 493us/step - loss: 0.5551 - val_loss: 0.5275\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 493us/step - loss: 0.5491 - val_loss: 0.5212\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 503us/step - loss: 0.5431 - val_loss: 0.5154\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 496us/step - loss: 0.5376 - val_loss: 0.5095\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 495us/step - loss: 0.5320 - val_loss: 0.5041\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 507us/step - loss: 0.5267 - val_loss: 0.4977\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 489us/step - loss: 0.5214 - val_loss: 0.4924\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 664us/step - loss: 0.5163 - val_loss: 0.4872\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 516us/step - loss: 0.5113 - val_loss: 0.4821\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 492us/step - loss: 0.5065 - val_loss: 0.4772\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 494us/step - loss: 0.5017 - val_loss: 0.4723\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 514us/step - loss: 0.4972 - val_loss: 0.4678\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 495us/step - loss: 0.4926 - val_loss: 0.4637\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 494us/step - loss: 0.4885 - val_loss: 0.4594\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 516us/step - loss: 0.4842 - val_loss: 0.4562\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 500us/step - loss: 0.4802 - val_loss: 0.4517\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 494us/step - loss: 0.4767 - val_loss: 0.4477\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 516us/step - loss: 0.4728 - val_loss: 0.4442\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 489us/step - loss: 0.4692 - val_loss: 0.4405\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 492us/step - loss: 0.4659 - val_loss: 0.4368\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 509us/step - loss: 0.4624 - val_loss: 0.4339\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 490us/step - loss: 0.4594 - val_loss: 0.4307\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 496us/step - loss: 0.4561 - val_loss: 0.4274\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 494us/step - loss: 0.4532 - val_loss: 0.4247\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 510us/step - loss: 0.4502 - val_loss: 0.4226\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 494us/step - loss: 0.4474 - val_loss: 0.4191\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 493us/step - loss: 0.4447 - val_loss: 0.4171\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 493us/step - loss: 0.4420 - val_loss: 0.4151\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 515us/step - loss: 0.4394 - val_loss: 0.4121\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 491us/step - loss: 0.4371 - val_loss: 0.4100\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 493us/step - loss: 0.4347 - val_loss: 0.4074\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 506us/step - loss: 0.4323 - val_loss: 0.4057\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 494us/step - loss: 0.4301 - val_loss: 0.4036\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 492us/step - loss: 0.4279 - val_loss: 0.4016\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 508us/step - loss: 0.4258 - val_loss: 0.3998\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 492us/step - loss: 0.4237 - val_loss: 0.3985\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 495us/step - loss: 0.4217 - val_loss: 0.3963\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 508us/step - loss: 0.4196 - val_loss: 0.3945\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 493us/step - loss: 0.4180 - val_loss: 0.3926\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 491us/step - loss: 0.4161 - val_loss: 0.3903\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 510us/step - loss: 0.4144 - val_loss: 0.3893\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 493us/step - loss: 0.4125 - val_loss: 0.3882\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 490us/step - loss: 0.4111 - val_loss: 0.3861\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 510us/step - loss: 0.4095 - val_loss: 0.3850\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 489us/step - loss: 0.4079 - val_loss: 0.3834\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 490us/step - loss: 0.4065 - val_loss: 0.3821\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 502us/step - loss: 0.4050 - val_loss: 0.3807\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 488us/step - loss: 0.4034 - val_loss: 0.3797\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 495us/step - loss: 0.4021 - val_loss: 0.3787\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 509us/step - loss: 0.4006 - val_loss: 0.3775\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 492us/step - loss: 0.3994 - val_loss: 0.3763\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 495us/step - loss: 0.3982 - val_loss: 0.3754\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 509us/step - loss: 0.3969 - val_loss: 0.3746\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 492us/step - loss: 0.3956 - val_loss: 0.3735\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 490us/step - loss: 0.3942 - val_loss: 0.3725\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 491us/step - loss: 0.3933 - val_loss: 0.3716\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 508us/step - loss: 0.3923 - val_loss: 0.3702\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 490us/step - loss: 0.3911 - val_loss: 0.3689\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 490us/step - loss: 0.3900 - val_loss: 0.3679\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 516us/step - loss: 0.3889 - val_loss: 0.3674\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 491us/step - loss: 0.3879 - val_loss: 0.3665\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 495us/step - loss: 0.3867 - val_loss: 0.3666\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 506us/step - loss: 0.3859 - val_loss: 0.3651\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 492us/step - loss: 0.3848 - val_loss: 0.3641\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 491us/step - loss: 0.3839 - val_loss: 0.3638\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 510us/step - loss: 0.3830 - val_loss: 0.3631\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 495us/step - loss: 0.3821 - val_loss: 0.3621\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 490us/step - loss: 0.3812 - val_loss: 0.3611\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 515us/step - loss: 0.3802 - val_loss: 0.3609\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 618us/step - loss: 0.3796 - val_loss: 0.3598\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 491us/step - loss: 0.3785 - val_loss: 0.3590\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 517us/step - loss: 0.3777 - val_loss: 0.3589\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 491us/step - loss: 0.3768 - val_loss: 0.3575\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 492us/step - loss: 0.3760 - val_loss: 0.3574\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 513us/step - loss: 0.3752 - val_loss: 0.3566\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 488us/step - loss: 0.3743 - val_loss: 0.3563\n",
      "121/121 [==============================] - 0s 282us/step - loss: 0.3618\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 568us/step - loss: 2.4986 - val_loss: 1.1903\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.8620 - val_loss: 0.7610\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 428us/step - loss: 0.6978 - val_loss: 0.6934\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 427us/step - loss: 0.6621 - val_loss: 0.6628\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 454us/step - loss: 0.6402 - val_loss: 0.6420\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 428us/step - loss: 0.6218 - val_loss: 0.6227\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 431us/step - loss: 0.6057 - val_loss: 0.6072\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.5912 - val_loss: 0.5922\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 431us/step - loss: 0.5777 - val_loss: 0.5783\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 429us/step - loss: 0.5654 - val_loss: 0.5659\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 451us/step - loss: 0.5539 - val_loss: 0.5534\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 426us/step - loss: 0.5435 - val_loss: 0.5440\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 429us/step - loss: 0.5341 - val_loss: 0.5337\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 0.5253 - val_loss: 0.5259\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 433us/step - loss: 0.5175 - val_loss: 0.5163\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 427us/step - loss: 0.5103 - val_loss: 0.5093\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.5037 - val_loss: 0.5028\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 431us/step - loss: 0.4978 - val_loss: 0.4972\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 429us/step - loss: 0.4923 - val_loss: 0.4918\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.4874 - val_loss: 0.4854\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 430us/step - loss: 0.4828 - val_loss: 0.4809\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 433us/step - loss: 0.4784 - val_loss: 0.4769\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 450us/step - loss: 0.4745 - val_loss: 0.4730\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 432us/step - loss: 0.4708 - val_loss: 0.4688\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 432us/step - loss: 0.4674 - val_loss: 0.4647\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 451us/step - loss: 0.4642 - val_loss: 0.4619\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 428us/step - loss: 0.4615 - val_loss: 0.4593\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 431us/step - loss: 0.4587 - val_loss: 0.4561\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 457us/step - loss: 0.4562 - val_loss: 0.4536\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 431us/step - loss: 0.4538 - val_loss: 0.4512\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 426us/step - loss: 0.4516 - val_loss: 0.4483\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.4494 - val_loss: 0.4457\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 427us/step - loss: 0.4474 - val_loss: 0.4436\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 430us/step - loss: 0.4454 - val_loss: 0.4421\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 426us/step - loss: 0.4436 - val_loss: 0.4404\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 449us/step - loss: 0.4417 - val_loss: 0.4373\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 430us/step - loss: 0.4400 - val_loss: 0.4360\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 455us/step - loss: 0.4384 - val_loss: 0.4344\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 574us/step - loss: 0.4368 - val_loss: 0.4331\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 432us/step - loss: 0.4352 - val_loss: 0.4308\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 456us/step - loss: 0.4338 - val_loss: 0.4304\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 430us/step - loss: 0.4324 - val_loss: 0.4291\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 432us/step - loss: 0.4311 - val_loss: 0.4275\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 442us/step - loss: 0.4297 - val_loss: 0.4251\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 430us/step - loss: 0.4285 - val_loss: 0.4243\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 428us/step - loss: 0.4270 - val_loss: 0.4216\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.4262 - val_loss: 0.4222\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 429us/step - loss: 0.4249 - val_loss: 0.4206\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 428us/step - loss: 0.4236 - val_loss: 0.4197\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.4225 - val_loss: 0.4179\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 434us/step - loss: 0.4214 - val_loss: 0.4170\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 427us/step - loss: 0.4202 - val_loss: 0.4166\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 548us/step - loss: 0.4192 - val_loss: 0.4149\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 431us/step - loss: 0.4181 - val_loss: 0.4141\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 430us/step - loss: 0.4169 - val_loss: 0.4120\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.4160 - val_loss: 0.4117\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 429us/step - loss: 0.4149 - val_loss: 0.4110\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 431us/step - loss: 0.4138 - val_loss: 0.4089\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 449us/step - loss: 0.4129 - val_loss: 0.4088\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 427us/step - loss: 0.4118 - val_loss: 0.4079\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 433us/step - loss: 0.4109 - val_loss: 0.4062\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.4099 - val_loss: 0.4053\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 429us/step - loss: 0.4086 - val_loss: 0.4044\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 0.4080 - val_loss: 0.4039\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 428us/step - loss: 0.4070 - val_loss: 0.4025\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 428us/step - loss: 0.4060 - val_loss: 0.4019\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.4051 - val_loss: 0.4010\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 429us/step - loss: 0.4043 - val_loss: 0.3999\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 431us/step - loss: 0.4033 - val_loss: 0.3992\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 451us/step - loss: 0.4026 - val_loss: 0.3982\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 428us/step - loss: 0.4017 - val_loss: 0.3971\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 430us/step - loss: 0.4009 - val_loss: 0.3964\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.4001 - val_loss: 0.3953\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 428us/step - loss: 0.3994 - val_loss: 0.3945\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 426us/step - loss: 0.3986 - val_loss: 0.3939\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.3979 - val_loss: 0.3935\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 427us/step - loss: 0.3971 - val_loss: 0.3929\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 429us/step - loss: 0.3963 - val_loss: 0.3914\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.3956 - val_loss: 0.3904\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 431us/step - loss: 0.3950 - val_loss: 0.3904\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 429us/step - loss: 0.3942 - val_loss: 0.3900\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.3936 - val_loss: 0.3887\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 439us/step - loss: 0.3930 - val_loss: 0.3878\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 596us/step - loss: 0.3923 - val_loss: 0.3872\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.3917 - val_loss: 0.3869\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 433us/step - loss: 0.3910 - val_loss: 0.3867\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.3904 - val_loss: 0.3855\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 427us/step - loss: 0.3898 - val_loss: 0.3853\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 429us/step - loss: 0.3892 - val_loss: 0.3852\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.3886 - val_loss: 0.3854\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 429us/step - loss: 0.3881 - val_loss: 0.3838\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 439us/step - loss: 0.3874 - val_loss: 0.3827\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 428us/step - loss: 0.3869 - val_loss: 0.3828\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 431us/step - loss: 0.3863 - val_loss: 0.3826\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 442us/step - loss: 0.3857 - val_loss: 0.3813\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 428us/step - loss: 0.3853 - val_loss: 0.3812\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 438us/step - loss: 0.3846 - val_loss: 0.3801\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 429us/step - loss: 0.3842 - val_loss: 0.3801\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 429us/step - loss: 0.3836 - val_loss: 0.3799\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 451us/step - loss: 0.3829 - val_loss: 0.3805\n",
      "121/121 [==============================] - 0s 270us/step - loss: 0.4248\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 566us/step - loss: 3.3260 - val_loss: 1.3799\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 431us/step - loss: 0.9772 - val_loss: 0.8015\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 457us/step - loss: 0.7321 - val_loss: 0.6968\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 433us/step - loss: 0.6784 - val_loss: 0.6586\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 533us/step - loss: 0.6523 - val_loss: 0.6337\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 455us/step - loss: 0.6330 - val_loss: 0.6147\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 432us/step - loss: 0.6159 - val_loss: 0.5976\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 429us/step - loss: 0.6011 - val_loss: 0.5826\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.5875 - val_loss: 0.5691\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 431us/step - loss: 0.5749 - val_loss: 0.5569\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 455us/step - loss: 0.5641 - val_loss: 0.5462\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 430us/step - loss: 0.5538 - val_loss: 0.5365\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 435us/step - loss: 0.5446 - val_loss: 0.5280\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 450us/step - loss: 0.5365 - val_loss: 0.5196\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 426us/step - loss: 0.5290 - val_loss: 0.5120\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 427us/step - loss: 0.5222 - val_loss: 0.5048\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 450us/step - loss: 0.5159 - val_loss: 0.4992\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 431us/step - loss: 0.5101 - val_loss: 0.4933\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 429us/step - loss: 0.5050 - val_loss: 0.4884\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.5003 - val_loss: 0.4832\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 430us/step - loss: 0.4958 - val_loss: 0.4791\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 429us/step - loss: 0.4917 - val_loss: 0.4745\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 449us/step - loss: 0.4880 - val_loss: 0.4713\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 427us/step - loss: 0.4843 - val_loss: 0.4666\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 429us/step - loss: 0.4812 - val_loss: 0.4633\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.4781 - val_loss: 0.4606\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 432us/step - loss: 0.4751 - val_loss: 0.4578\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 431us/step - loss: 0.4725 - val_loss: 0.4545\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 449us/step - loss: 0.4699 - val_loss: 0.4524\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 429us/step - loss: 0.4674 - val_loss: 0.4490\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.4653 - val_loss: 0.4467\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 431us/step - loss: 0.4632 - val_loss: 0.4452\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 426us/step - loss: 0.4611 - val_loss: 0.4422\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 454us/step - loss: 0.4590 - val_loss: 0.4406\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 433us/step - loss: 0.4571 - val_loss: 0.4384\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 432us/step - loss: 0.4554 - val_loss: 0.4366\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 0.4537 - val_loss: 0.4347\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 430us/step - loss: 0.4519 - val_loss: 0.4334\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 432us/step - loss: 0.4503 - val_loss: 0.4315\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.4488 - val_loss: 0.4301\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 425us/step - loss: 0.4474 - val_loss: 0.4285\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 430us/step - loss: 0.4460 - val_loss: 0.4270\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 452us/step - loss: 0.4445 - val_loss: 0.4254\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 428us/step - loss: 0.4432 - val_loss: 0.4242\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 431us/step - loss: 0.4418 - val_loss: 0.4231\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.4406 - val_loss: 0.4217\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 428us/step - loss: 0.4392 - val_loss: 0.4204\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 426us/step - loss: 0.4384 - val_loss: 0.4192\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 0.4371 - val_loss: 0.4179\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 431us/step - loss: 0.4358 - val_loss: 0.4174\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 430us/step - loss: 0.4347 - val_loss: 0.4162\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 450us/step - loss: 0.4337 - val_loss: 0.4144\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 431us/step - loss: 0.4326 - val_loss: 0.4133\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 427us/step - loss: 0.4316 - val_loss: 0.4121\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 449us/step - loss: 0.4305 - val_loss: 0.4112\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 429us/step - loss: 0.4296 - val_loss: 0.4108\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 430us/step - loss: 0.4284 - val_loss: 0.4097\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 450us/step - loss: 0.4275 - val_loss: 0.4088\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 429us/step - loss: 0.4265 - val_loss: 0.4077\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 511us/step - loss: 0.4256 - val_loss: 0.4065\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 452us/step - loss: 0.4246 - val_loss: 0.4062\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 428us/step - loss: 0.4237 - val_loss: 0.4050\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 429us/step - loss: 0.4229 - val_loss: 0.4042\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 443us/step - loss: 0.4219 - val_loss: 0.4029\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 426us/step - loss: 0.4211 - val_loss: 0.4022\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 429us/step - loss: 0.4203 - val_loss: 0.4026\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.4193 - val_loss: 0.4013\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 429us/step - loss: 0.4187 - val_loss: 0.4008\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.4179 - val_loss: 0.3996\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 430us/step - loss: 0.4171 - val_loss: 0.3990\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 426us/step - loss: 0.4163 - val_loss: 0.3980\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 449us/step - loss: 0.4157 - val_loss: 0.3977\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 427us/step - loss: 0.4150 - val_loss: 0.3973\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.4142 - val_loss: 0.3970\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 429us/step - loss: 0.4136 - val_loss: 0.3961\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 430us/step - loss: 0.4131 - val_loss: 0.3950\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 427us/step - loss: 0.4124 - val_loss: 0.3945\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 450us/step - loss: 0.4117 - val_loss: 0.3940\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 430us/step - loss: 0.4110 - val_loss: 0.3936\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 441us/step - loss: 0.4104 - val_loss: 0.3924\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 431us/step - loss: 0.4097 - val_loss: 0.3918\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 430us/step - loss: 0.4093 - val_loss: 0.3918\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 443us/step - loss: 0.4086 - val_loss: 0.3912\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 430us/step - loss: 0.4081 - val_loss: 0.3907\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.4074 - val_loss: 0.3895\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 428us/step - loss: 0.4068 - val_loss: 0.3894\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 430us/step - loss: 0.4063 - val_loss: 0.3890\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.4057 - val_loss: 0.3887\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 429us/step - loss: 0.4052 - val_loss: 0.3876\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 449us/step - loss: 0.4048 - val_loss: 0.3874\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 428us/step - loss: 0.4041 - val_loss: 0.3870\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 470us/step - loss: 0.4036 - val_loss: 0.3870\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.4032 - val_loss: 0.3865\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 432us/step - loss: 0.4025 - val_loss: 0.3858\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 430us/step - loss: 0.4021 - val_loss: 0.3856\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.4014 - val_loss: 0.3853\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 430us/step - loss: 0.4011 - val_loss: 0.3846\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 430us/step - loss: 0.4007 - val_loss: 0.3845\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.4001 - val_loss: 0.3840\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 425us/step - loss: 0.3994 - val_loss: 0.3834\n",
      "121/121 [==============================] - 0s 267us/step - loss: 0.4005\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 571us/step - loss: 2.9928 - val_loss: 1.5065\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 454us/step - loss: 1.1134 - val_loss: 0.8567\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 431us/step - loss: 0.7883 - val_loss: 0.7149\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 455us/step - loss: 0.7084 - val_loss: 0.6633\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 464us/step - loss: 0.6754 - val_loss: 0.6364\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 433us/step - loss: 0.6536 - val_loss: 0.6153\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.6351 - val_loss: 0.5969\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 432us/step - loss: 0.6189 - val_loss: 0.5813\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 430us/step - loss: 0.6042 - val_loss: 0.5666\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.5905 - val_loss: 0.5536\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 437us/step - loss: 0.5788 - val_loss: 0.5426\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 449us/step - loss: 0.5679 - val_loss: 0.5321\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 429us/step - loss: 0.5580 - val_loss: 0.5225\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.5492 - val_loss: 0.5149\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 429us/step - loss: 0.5410 - val_loss: 0.5074\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 0.5336 - val_loss: 0.4993\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 428us/step - loss: 0.5271 - val_loss: 0.4927\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 443us/step - loss: 0.5210 - val_loss: 0.4875\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 602us/step - loss: 0.5153 - val_loss: 0.4822\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 430us/step - loss: 0.5101 - val_loss: 0.4776\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 449us/step - loss: 0.5054 - val_loss: 0.4722\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 429us/step - loss: 0.5008 - val_loss: 0.4678\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 451us/step - loss: 0.4969 - val_loss: 0.4647\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 429us/step - loss: 0.4932 - val_loss: 0.4607\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 0.4897 - val_loss: 0.4581\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 434us/step - loss: 0.4865 - val_loss: 0.4542\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 443us/step - loss: 0.4834 - val_loss: 0.4521\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 427us/step - loss: 0.4805 - val_loss: 0.4491\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 0.4780 - val_loss: 0.4468\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 432us/step - loss: 0.4754 - val_loss: 0.4439\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.4731 - val_loss: 0.4415\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 433us/step - loss: 0.4709 - val_loss: 0.4395\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 441us/step - loss: 0.4687 - val_loss: 0.4376\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 430us/step - loss: 0.4667 - val_loss: 0.4355\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 434us/step - loss: 0.4648 - val_loss: 0.4333\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 450us/step - loss: 0.4629 - val_loss: 0.4319\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 432us/step - loss: 0.4612 - val_loss: 0.4308\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 458us/step - loss: 0.4595 - val_loss: 0.4287\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 428us/step - loss: 0.4578 - val_loss: 0.4276\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 429us/step - loss: 0.4563 - val_loss: 0.4258\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 0.4548 - val_loss: 0.4245\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 431us/step - loss: 0.4535 - val_loss: 0.4229\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 459us/step - loss: 0.4520 - val_loss: 0.4222\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 433us/step - loss: 0.4506 - val_loss: 0.4205\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 452us/step - loss: 0.4494 - val_loss: 0.4195\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 432us/step - loss: 0.4481 - val_loss: 0.4176\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.4470 - val_loss: 0.4169\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 431us/step - loss: 0.4457 - val_loss: 0.4152\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 433us/step - loss: 0.4445 - val_loss: 0.4141\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.4435 - val_loss: 0.4136\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 431us/step - loss: 0.4424 - val_loss: 0.4127\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 451us/step - loss: 0.4412 - val_loss: 0.4110\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 434us/step - loss: 0.4403 - val_loss: 0.4106\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.4392 - val_loss: 0.4096\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 428us/step - loss: 0.4382 - val_loss: 0.4086\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 449us/step - loss: 0.4374 - val_loss: 0.4077\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 432us/step - loss: 0.4364 - val_loss: 0.4068\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 433us/step - loss: 0.4354 - val_loss: 0.4055\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 429us/step - loss: 0.4346 - val_loss: 0.4053\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 430us/step - loss: 0.4337 - val_loss: 0.4041\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 453us/step - loss: 0.4327 - val_loss: 0.4028\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 429us/step - loss: 0.4319 - val_loss: 0.4025\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.4312 - val_loss: 0.4023\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 428us/step - loss: 0.4303 - val_loss: 0.4014\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 449us/step - loss: 0.4295 - val_loss: 0.4008\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 432us/step - loss: 0.4288 - val_loss: 0.3995\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 458us/step - loss: 0.4280 - val_loss: 0.3987\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 431us/step - loss: 0.4274 - val_loss: 0.3978\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.4266 - val_loss: 0.3972\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 429us/step - loss: 0.4258 - val_loss: 0.3967\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 526us/step - loss: 0.4250 - val_loss: 0.3961\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 429us/step - loss: 0.4243 - val_loss: 0.3959\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 437us/step - loss: 0.4238 - val_loss: 0.3943\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 426us/step - loss: 0.4229 - val_loss: 0.3942\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 430us/step - loss: 0.4223 - val_loss: 0.3938\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 543us/step - loss: 0.4216 - val_loss: 0.3927\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 425us/step - loss: 0.4210 - val_loss: 0.3915\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 453us/step - loss: 0.4202 - val_loss: 0.3911\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 427us/step - loss: 0.4195 - val_loss: 0.3916\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.4189 - val_loss: 0.3906\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 430us/step - loss: 0.4184 - val_loss: 0.3903\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 449us/step - loss: 0.4177 - val_loss: 0.3895\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 428us/step - loss: 0.4171 - val_loss: 0.3890\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.4164 - val_loss: 0.3889\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 427us/step - loss: 0.4159 - val_loss: 0.3875\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.4153 - val_loss: 0.3876\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 430us/step - loss: 0.4147 - val_loss: 0.3869\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.4140 - val_loss: 0.3856\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 435us/step - loss: 0.4136 - val_loss: 0.3851\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 431us/step - loss: 0.4129 - val_loss: 0.3849\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 449us/step - loss: 0.4124 - val_loss: 0.3843\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 433us/step - loss: 0.4118 - val_loss: 0.3837\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 452us/step - loss: 0.4113 - val_loss: 0.3834\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 425us/step - loss: 0.4105 - val_loss: 0.3827\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 451us/step - loss: 0.4101 - val_loss: 0.3828\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 426us/step - loss: 0.4095 - val_loss: 0.3823\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 452us/step - loss: 0.4091 - val_loss: 0.3810\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 434us/step - loss: 0.4085 - val_loss: 0.3805\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.4080 - val_loss: 0.3807\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 433us/step - loss: 0.4075 - val_loss: 0.3796\n",
      "121/121 [==============================] - 0s 270us/step - loss: 0.3861\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 556us/step - loss: 3.3773 - val_loss: 1.7507\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 407us/step - loss: 1.2386 - val_loss: 0.8891\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 406us/step - loss: 0.7487 - val_loss: 0.6758\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 429us/step - loss: 0.6263 - val_loss: 0.6138\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 408us/step - loss: 0.5899 - val_loss: 0.5840\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 424us/step - loss: 0.5771 - val_loss: 0.5788\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 404us/step - loss: 0.5682 - val_loss: 0.5659\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 423us/step - loss: 0.5634 - val_loss: 0.5610\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 588us/step - loss: 0.5585 - val_loss: 0.5615\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 983us/step - loss: 0.5536 - val_loss: 0.5611\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 409us/step - loss: 0.5497 - val_loss: 0.5599\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 430us/step - loss: 0.5462 - val_loss: 0.5545\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 405us/step - loss: 0.5426 - val_loss: 0.5522\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 424us/step - loss: 0.5391 - val_loss: 0.5422\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 405us/step - loss: 0.5370 - val_loss: 0.5441\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 426us/step - loss: 0.5344 - val_loss: 0.5444\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 409us/step - loss: 0.5319 - val_loss: 0.5452\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 424us/step - loss: 0.5295 - val_loss: 0.5353\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 403us/step - loss: 0.5276 - val_loss: 0.5428\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 420us/step - loss: 0.5260 - val_loss: 0.5338\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 408us/step - loss: 0.5249 - val_loss: 0.5374\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 429us/step - loss: 0.5234 - val_loss: 0.5316\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 401us/step - loss: 0.5215 - val_loss: 0.5366\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 535us/step - loss: 0.5210 - val_loss: 0.5343\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 408us/step - loss: 0.5197 - val_loss: 0.5368\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 419us/step - loss: 0.5182 - val_loss: 0.5260\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 404us/step - loss: 0.5182 - val_loss: 0.5309\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 425us/step - loss: 0.5169 - val_loss: 0.5262\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 407us/step - loss: 0.5164 - val_loss: 0.5260\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 422us/step - loss: 0.5157 - val_loss: 0.5280\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 405us/step - loss: 0.5150 - val_loss: 0.5258\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 422us/step - loss: 0.5146 - val_loss: 0.5261\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 401us/step - loss: 0.5140 - val_loss: 0.5318\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 422us/step - loss: 0.5135 - val_loss: 0.5276\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 404us/step - loss: 0.5130 - val_loss: 0.5254\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 424us/step - loss: 0.5128 - val_loss: 0.5256\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 402us/step - loss: 0.5119 - val_loss: 0.5222\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 422us/step - loss: 0.5120 - val_loss: 0.5250\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 408us/step - loss: 0.5115 - val_loss: 0.5266\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 422us/step - loss: 0.5113 - val_loss: 0.5260\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 406us/step - loss: 0.5110 - val_loss: 0.5255\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 427us/step - loss: 0.5106 - val_loss: 0.5297\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 407us/step - loss: 0.5108 - val_loss: 0.5260\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 424us/step - loss: 0.5103 - val_loss: 0.5288\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 406us/step - loss: 0.5102 - val_loss: 0.5287\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 425us/step - loss: 0.5100 - val_loss: 0.5318\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 405us/step - loss: 0.5099 - val_loss: 0.5304\n",
      "121/121 [==============================] - 0s 260us/step - loss: 0.5496\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 559us/step - loss: 4.2109 - val_loss: 2.0570\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 412us/step - loss: 1.3244 - val_loss: 0.8823\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 425us/step - loss: 0.7130 - val_loss: 0.6055\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 417us/step - loss: 0.5709 - val_loss: 0.5366\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 421us/step - loss: 0.5366 - val_loss: 0.5186\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 410us/step - loss: 0.5275 - val_loss: 0.5143\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 420us/step - loss: 0.5252 - val_loss: 0.5123\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 409us/step - loss: 0.5241 - val_loss: 0.5105\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 420us/step - loss: 0.5243 - val_loss: 0.5109\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 407us/step - loss: 0.5241 - val_loss: 0.5122\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 425us/step - loss: 0.5241 - val_loss: 0.5128\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 411us/step - loss: 0.5240 - val_loss: 0.5141\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 420us/step - loss: 0.5242 - val_loss: 0.5118\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 407us/step - loss: 0.5241 - val_loss: 0.5122\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 419us/step - loss: 0.5240 - val_loss: 0.5130\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 408us/step - loss: 0.5240 - val_loss: 0.5126\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 419us/step - loss: 0.5239 - val_loss: 0.5135\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 408us/step - loss: 0.5237 - val_loss: 0.5108\n",
      "121/121 [==============================] - 0s 257us/step - loss: 0.5196\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 542us/step - loss: 4.0961 - val_loss: 2.0083\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 433us/step - loss: 1.4401 - val_loss: 1.0229\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 412us/step - loss: 0.9117 - val_loss: 0.7869\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 425us/step - loss: 0.7758 - val_loss: 0.7167\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 403us/step - loss: 0.7288 - val_loss: 0.6870\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 430us/step - loss: 0.7038 - val_loss: 0.6663\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 413us/step - loss: 0.6862 - val_loss: 0.6500\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 428us/step - loss: 0.6708 - val_loss: 0.6390\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 408us/step - loss: 0.6574 - val_loss: 0.6257\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 426us/step - loss: 0.6452 - val_loss: 0.6140\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 410us/step - loss: 0.6343 - val_loss: 0.6047\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 507us/step - loss: 0.6241 - val_loss: 0.5948\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 414us/step - loss: 0.6154 - val_loss: 0.5864\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 429us/step - loss: 0.6078 - val_loss: 0.5824\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 409us/step - loss: 0.6000 - val_loss: 0.5792\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 427us/step - loss: 0.5935 - val_loss: 0.5753\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 408us/step - loss: 0.5877 - val_loss: 0.5655\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 423us/step - loss: 0.5822 - val_loss: 0.5634\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 413us/step - loss: 0.5775 - val_loss: 0.5628\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 425us/step - loss: 0.5729 - val_loss: 0.5589\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 407us/step - loss: 0.5690 - val_loss: 0.5524\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 428us/step - loss: 0.5656 - val_loss: 0.5493\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 410us/step - loss: 0.5622 - val_loss: 0.5480\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 425us/step - loss: 0.5587 - val_loss: 0.5485\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 411us/step - loss: 0.5556 - val_loss: 0.5388\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 430us/step - loss: 0.5543 - val_loss: 0.5399\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 409us/step - loss: 0.5513 - val_loss: 0.5351\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 429us/step - loss: 0.5494 - val_loss: 0.5423\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 410us/step - loss: 0.5478 - val_loss: 0.5374\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 428us/step - loss: 0.5461 - val_loss: 0.5338\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 413us/step - loss: 0.5446 - val_loss: 0.5383\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 428us/step - loss: 0.5435 - val_loss: 0.5346\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 406us/step - loss: 0.5421 - val_loss: 0.5323\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 426us/step - loss: 0.5410 - val_loss: 0.5352\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 409us/step - loss: 0.5398 - val_loss: 0.5383\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 427us/step - loss: 0.5391 - val_loss: 0.5359\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 409us/step - loss: 0.5380 - val_loss: 0.5318\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 430us/step - loss: 0.5372 - val_loss: 0.5345\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 408us/step - loss: 0.5366 - val_loss: 0.5334\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 431us/step - loss: 0.5359 - val_loss: 0.5301\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 409us/step - loss: 0.5350 - val_loss: 0.5262\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 428us/step - loss: 0.5350 - val_loss: 0.5327\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 410us/step - loss: 0.5344 - val_loss: 0.5326\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 424us/step - loss: 0.5339 - val_loss: 0.5299\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 407us/step - loss: 0.5332 - val_loss: 0.5286\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 432us/step - loss: 0.5329 - val_loss: 0.5291\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 410us/step - loss: 0.5330 - val_loss: 0.5309\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 428us/step - loss: 0.5322 - val_loss: 0.5321\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 413us/step - loss: 0.5322 - val_loss: 0.5318\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 431us/step - loss: 0.5319 - val_loss: 0.5303\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 408us/step - loss: 0.5314 - val_loss: 0.5273\n",
      "121/121 [==============================] - 0s 261us/step - loss: 0.5073\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.6938 - val_loss: 2.1427\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 466us/step - loss: 1.4652 - val_loss: 1.1991\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 0.9921 - val_loss: 0.9451\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 464us/step - loss: 0.8456 - val_loss: 0.8344\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.7733 - val_loss: 0.7723\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 465us/step - loss: 0.7310 - val_loss: 0.7331\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 492us/step - loss: 0.7034 - val_loss: 0.7059\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 466us/step - loss: 0.6834 - val_loss: 0.6857\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.6673 - val_loss: 0.6689\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 461us/step - loss: 0.6533 - val_loss: 0.6537\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.6411 - val_loss: 0.6407\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 463us/step - loss: 0.6298 - val_loss: 0.6286\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.6195 - val_loss: 0.6177\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 462us/step - loss: 0.6098 - val_loss: 0.6076\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.6009 - val_loss: 0.5981\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 461us/step - loss: 0.5924 - val_loss: 0.5891\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 478us/step - loss: 0.5844 - val_loss: 0.5804\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 463us/step - loss: 0.5767 - val_loss: 0.5720\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 0.5693 - val_loss: 0.5641\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 554us/step - loss: 0.5623 - val_loss: 0.5567\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.5556 - val_loss: 0.5499\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 460us/step - loss: 0.5491 - val_loss: 0.5428\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.5428 - val_loss: 0.5361\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 464us/step - loss: 0.5370 - val_loss: 0.5300\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.5312 - val_loss: 0.5239\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 461us/step - loss: 0.5257 - val_loss: 0.5181\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.5203 - val_loss: 0.5124\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 460us/step - loss: 0.5154 - val_loss: 0.5072\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 477us/step - loss: 0.5104 - val_loss: 0.5026\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 463us/step - loss: 0.5057 - val_loss: 0.4976\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 510us/step - loss: 0.5012 - val_loss: 0.4925\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 464us/step - loss: 0.4971 - val_loss: 0.4881\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 478us/step - loss: 0.4930 - val_loss: 0.4842\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 465us/step - loss: 0.4890 - val_loss: 0.4798\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 0.4853 - val_loss: 0.4762\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 461us/step - loss: 0.4817 - val_loss: 0.4726\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 488us/step - loss: 0.4783 - val_loss: 0.4694\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 465us/step - loss: 0.4752 - val_loss: 0.4657\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 0.4721 - val_loss: 0.4628\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 544us/step - loss: 0.4692 - val_loss: 0.4597\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.4664 - val_loss: 0.4568\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 467us/step - loss: 0.4635 - val_loss: 0.4537\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 476us/step - loss: 0.4611 - val_loss: 0.4515\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 467us/step - loss: 0.4586 - val_loss: 0.4490\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 0.4563 - val_loss: 0.4461\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 464us/step - loss: 0.4540 - val_loss: 0.4439\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.4518 - val_loss: 0.4417\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 460us/step - loss: 0.4497 - val_loss: 0.4397\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 478us/step - loss: 0.4478 - val_loss: 0.4377\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 462us/step - loss: 0.4458 - val_loss: 0.4361\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.4441 - val_loss: 0.4343\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 462us/step - loss: 0.4423 - val_loss: 0.4326\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 486us/step - loss: 0.4406 - val_loss: 0.4311\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 462us/step - loss: 0.4390 - val_loss: 0.4291\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.4374 - val_loss: 0.4273\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 464us/step - loss: 0.4359 - val_loss: 0.4260\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 477us/step - loss: 0.4344 - val_loss: 0.4248\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 463us/step - loss: 0.4330 - val_loss: 0.4231\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.4316 - val_loss: 0.4217\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 461us/step - loss: 0.4303 - val_loss: 0.4201\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 489us/step - loss: 0.4290 - val_loss: 0.4188\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 465us/step - loss: 0.4278 - val_loss: 0.4181\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 0.4266 - val_loss: 0.4170\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 463us/step - loss: 0.4254 - val_loss: 0.4154\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.4243 - val_loss: 0.4145\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 463us/step - loss: 0.4232 - val_loss: 0.4135\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 477us/step - loss: 0.4222 - val_loss: 0.4125\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 465us/step - loss: 0.4211 - val_loss: 0.4115\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.4201 - val_loss: 0.4109\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 465us/step - loss: 0.4192 - val_loss: 0.4097\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 0.4182 - val_loss: 0.4086\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 464us/step - loss: 0.4173 - val_loss: 0.4079\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 0.4164 - val_loss: 0.4068\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 461us/step - loss: 0.4155 - val_loss: 0.4062\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 563us/step - loss: 0.4147 - val_loss: 0.4054\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 464us/step - loss: 0.4138 - val_loss: 0.4043\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 0.4130 - val_loss: 0.4033\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 463us/step - loss: 0.4122 - val_loss: 0.4025\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.4113 - val_loss: 0.4017\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 521us/step - loss: 0.4106 - val_loss: 0.4007\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.4098 - val_loss: 0.4001\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 464us/step - loss: 0.4090 - val_loss: 0.3997\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 478us/step - loss: 0.4083 - val_loss: 0.3993\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 465us/step - loss: 0.4076 - val_loss: 0.3982\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.4069 - val_loss: 0.3983\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 464us/step - loss: 0.4062 - val_loss: 0.3977\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 0.4055 - val_loss: 0.3968\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 465us/step - loss: 0.4048 - val_loss: 0.3959\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.4042 - val_loss: 0.3952\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 463us/step - loss: 0.4035 - val_loss: 0.3950\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.4028 - val_loss: 0.3941\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 464us/step - loss: 0.4022 - val_loss: 0.3932\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 478us/step - loss: 0.4016 - val_loss: 0.3928\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 460us/step - loss: 0.4010 - val_loss: 0.3921\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.4004 - val_loss: 0.3918\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 464us/step - loss: 0.3998 - val_loss: 0.3915\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 0.3992 - val_loss: 0.3906\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 463us/step - loss: 0.3986 - val_loss: 0.3897\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.3980 - val_loss: 0.3897\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 456us/step - loss: 0.3974 - val_loss: 0.3897\n",
      "121/121 [==============================] - 0s 275us/step - loss: 0.4387\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 621us/step - loss: 4.0173 - val_loss: 2.8649\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 471us/step - loss: 2.1427 - val_loss: 1.7292\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 1.4116 - val_loss: 1.2681\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 464us/step - loss: 1.0817 - val_loss: 1.0208\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 478us/step - loss: 0.9064 - val_loss: 0.8748\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 474us/step - loss: 0.8011 - val_loss: 0.7816\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 498us/step - loss: 0.7357 - val_loss: 0.7217\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 469us/step - loss: 0.6938 - val_loss: 0.6812\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.6660 - val_loss: 0.6533\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 466us/step - loss: 0.6462 - val_loss: 0.6327\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 476us/step - loss: 0.6312 - val_loss: 0.6163\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 466us/step - loss: 0.6190 - val_loss: 0.6032\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 478us/step - loss: 0.6085 - val_loss: 0.5920\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 468us/step - loss: 0.5991 - val_loss: 0.5819\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 478us/step - loss: 0.5905 - val_loss: 0.5727\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 467us/step - loss: 0.5825 - val_loss: 0.5644\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 0.5751 - val_loss: 0.5567\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 467us/step - loss: 0.5681 - val_loss: 0.5495\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.5616 - val_loss: 0.5427\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 461us/step - loss: 0.5553 - val_loss: 0.5365\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.5495 - val_loss: 0.5305\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 466us/step - loss: 0.5440 - val_loss: 0.5248\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 561us/step - loss: 0.5387 - val_loss: 0.5193\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 468us/step - loss: 0.5337 - val_loss: 0.5143\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.5289 - val_loss: 0.5094\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 463us/step - loss: 0.5244 - val_loss: 0.5048\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.5202 - val_loss: 0.5005\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 466us/step - loss: 0.5162 - val_loss: 0.4964\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 495us/step - loss: 0.5123 - val_loss: 0.4925\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 934us/step - loss: 0.5086 - val_loss: 0.4888\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 478us/step - loss: 0.5050 - val_loss: 0.4851\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 465us/step - loss: 0.5015 - val_loss: 0.4818\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 0.4985 - val_loss: 0.4784\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 466us/step - loss: 0.4954 - val_loss: 0.4753\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 0.4925 - val_loss: 0.4723\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 462us/step - loss: 0.4897 - val_loss: 0.4695\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 0.4870 - val_loss: 0.4669\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 463us/step - loss: 0.4845 - val_loss: 0.4642\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.4821 - val_loss: 0.4617\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 464us/step - loss: 0.4797 - val_loss: 0.4593\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.4775 - val_loss: 0.4570\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 486us/step - loss: 0.4754 - val_loss: 0.4549\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.4733 - val_loss: 0.4528\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 466us/step - loss: 0.4713 - val_loss: 0.4509\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.4694 - val_loss: 0.4490\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 469us/step - loss: 0.4676 - val_loss: 0.4470\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.4658 - val_loss: 0.4451\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 462us/step - loss: 0.4642 - val_loss: 0.4434\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 0.4625 - val_loss: 0.4417\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 464us/step - loss: 0.4609 - val_loss: 0.4401\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.4594 - val_loss: 0.4385\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 466us/step - loss: 0.4578 - val_loss: 0.4370\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.4565 - val_loss: 0.4355\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 462us/step - loss: 0.4550 - val_loss: 0.4342\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.4537 - val_loss: 0.4328\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 468us/step - loss: 0.4523 - val_loss: 0.4316\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 488us/step - loss: 0.4511 - val_loss: 0.4303\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 465us/step - loss: 0.4498 - val_loss: 0.4289\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.4486 - val_loss: 0.4278\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 465us/step - loss: 0.4474 - val_loss: 0.4266\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.4462 - val_loss: 0.4256\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 462us/step - loss: 0.4451 - val_loss: 0.4244\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 491us/step - loss: 0.4440 - val_loss: 0.4233\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 469us/step - loss: 0.4429 - val_loss: 0.4220\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.4419 - val_loss: 0.4211\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 466us/step - loss: 0.4409 - val_loss: 0.4201\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 485us/step - loss: 0.4399 - val_loss: 0.4191\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 465us/step - loss: 0.4389 - val_loss: 0.4182\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 556us/step - loss: 0.4380 - val_loss: 0.4173\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 467us/step - loss: 0.4371 - val_loss: 0.4163\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 476us/step - loss: 0.4362 - val_loss: 0.4154\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 465us/step - loss: 0.4353 - val_loss: 0.4146\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 0.4344 - val_loss: 0.4138\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 465us/step - loss: 0.4336 - val_loss: 0.4129\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.4327 - val_loss: 0.4121\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 465us/step - loss: 0.4319 - val_loss: 0.4112\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.4311 - val_loss: 0.4105\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 527us/step - loss: 0.4303 - val_loss: 0.4098\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.4295 - val_loss: 0.4091\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 463us/step - loss: 0.4288 - val_loss: 0.4084\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 502us/step - loss: 0.4280 - val_loss: 0.4077\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 467us/step - loss: 0.4273 - val_loss: 0.4070\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 476us/step - loss: 0.4265 - val_loss: 0.4062\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 466us/step - loss: 0.4259 - val_loss: 0.4055\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 497us/step - loss: 0.4252 - val_loss: 0.4048\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 541us/step - loss: 0.4244 - val_loss: 0.4040\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 549us/step - loss: 0.4238 - val_loss: 0.4035\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.4231 - val_loss: 0.4028\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 512us/step - loss: 0.4225 - val_loss: 0.4023\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 466us/step - loss: 0.4218 - val_loss: 0.4016\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 485us/step - loss: 0.4211 - val_loss: 0.4011\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 465us/step - loss: 0.4205 - val_loss: 0.4004\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.4199 - val_loss: 0.3997\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 576us/step - loss: 0.4193 - val_loss: 0.3990\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 490us/step - loss: 0.4187 - val_loss: 0.3985\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 471us/step - loss: 0.4181 - val_loss: 0.3977\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 488us/step - loss: 0.4174 - val_loss: 0.3973\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 464us/step - loss: 0.4168 - val_loss: 0.3966\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 0.4163 - val_loss: 0.3962\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 464us/step - loss: 0.4157 - val_loss: 0.3955\n",
      "121/121 [==============================] - 0s 291us/step - loss: 0.4189\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 739us/step - loss: 4.1255 - val_loss: 2.8557\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 469us/step - loss: 2.1954 - val_loss: 1.7149\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 494us/step - loss: 1.4194 - val_loss: 1.2068\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 512us/step - loss: 1.1034 - val_loss: 0.9874\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 486us/step - loss: 0.9283 - val_loss: 0.8622\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 464us/step - loss: 0.8308 - val_loss: 0.7869\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 495us/step - loss: 0.7729 - val_loss: 0.7389\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 466us/step - loss: 0.7372 - val_loss: 0.7081\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 0.7138 - val_loss: 0.6856\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 468us/step - loss: 0.6969 - val_loss: 0.6691\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 486us/step - loss: 0.6835 - val_loss: 0.6559\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 468us/step - loss: 0.6721 - val_loss: 0.6439\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 488us/step - loss: 0.6618 - val_loss: 0.6333\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 466us/step - loss: 0.6524 - val_loss: 0.6236\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 486us/step - loss: 0.6439 - val_loss: 0.6155\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 467us/step - loss: 0.6354 - val_loss: 0.6073\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 548us/step - loss: 0.6277 - val_loss: 0.5994\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 467us/step - loss: 0.6202 - val_loss: 0.5920\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 0.6131 - val_loss: 0.5851\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 462us/step - loss: 0.6064 - val_loss: 0.5789\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.5997 - val_loss: 0.5722\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 463us/step - loss: 0.5935 - val_loss: 0.5665\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 0.5874 - val_loss: 0.5603\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 463us/step - loss: 0.5819 - val_loss: 0.5546\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 0.5765 - val_loss: 0.5497\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 467us/step - loss: 0.5712 - val_loss: 0.5445\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 486us/step - loss: 0.5662 - val_loss: 0.5397\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 467us/step - loss: 0.5614 - val_loss: 0.5346\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 0.5569 - val_loss: 0.5303\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 466us/step - loss: 0.5525 - val_loss: 0.5263\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 469us/step - loss: 0.5483 - val_loss: 0.5221\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 469us/step - loss: 0.5442 - val_loss: 0.5179\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 485us/step - loss: 0.5403 - val_loss: 0.5146\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 465us/step - loss: 0.5366 - val_loss: 0.5103\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.5331 - val_loss: 0.5070\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 466us/step - loss: 0.5297 - val_loss: 0.5038\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 485us/step - loss: 0.5265 - val_loss: 0.5008\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 466us/step - loss: 0.5233 - val_loss: 0.4977\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 547us/step - loss: 0.5203 - val_loss: 0.4949\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 467us/step - loss: 0.5174 - val_loss: 0.4917\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 487us/step - loss: 0.5146 - val_loss: 0.4893\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 473us/step - loss: 0.5121 - val_loss: 0.4864\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.5096 - val_loss: 0.4838\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 471us/step - loss: 0.5071 - val_loss: 0.4817\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 609us/step - loss: 0.5048 - val_loss: 0.4794\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 472us/step - loss: 0.5026 - val_loss: 0.4769\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.5004 - val_loss: 0.4751\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 467us/step - loss: 0.4984 - val_loss: 0.4726\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 485us/step - loss: 0.4965 - val_loss: 0.4708\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 468us/step - loss: 0.4945 - val_loss: 0.4691\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 488us/step - loss: 0.4927 - val_loss: 0.4671\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 470us/step - loss: 0.4909 - val_loss: 0.4654\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.4892 - val_loss: 0.4641\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 467us/step - loss: 0.4875 - val_loss: 0.4621\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 486us/step - loss: 0.4858 - val_loss: 0.4606\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 464us/step - loss: 0.4842 - val_loss: 0.4590\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.4827 - val_loss: 0.4579\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 466us/step - loss: 0.4812 - val_loss: 0.4561\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 487us/step - loss: 0.4797 - val_loss: 0.4551\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 466us/step - loss: 0.4784 - val_loss: 0.4534\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 485us/step - loss: 0.4770 - val_loss: 0.4521\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 464us/step - loss: 0.4756 - val_loss: 0.4508\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 487us/step - loss: 0.4744 - val_loss: 0.4494\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 466us/step - loss: 0.4730 - val_loss: 0.4485\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.4719 - val_loss: 0.4470\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 463us/step - loss: 0.4706 - val_loss: 0.4457\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.4694 - val_loss: 0.4444\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 465us/step - loss: 0.4682 - val_loss: 0.4436\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 486us/step - loss: 0.4671 - val_loss: 0.4426\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 466us/step - loss: 0.4660 - val_loss: 0.4414\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 0.4650 - val_loss: 0.4402\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 463us/step - loss: 0.4638 - val_loss: 0.4391\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 486us/step - loss: 0.4627 - val_loss: 0.4381\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 467us/step - loss: 0.4617 - val_loss: 0.4373\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.4606 - val_loss: 0.4366\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 465us/step - loss: 0.4596 - val_loss: 0.4352\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 486us/step - loss: 0.4587 - val_loss: 0.4342\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 466us/step - loss: 0.4576 - val_loss: 0.4338\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.4568 - val_loss: 0.4329\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 463us/step - loss: 0.4558 - val_loss: 0.4316\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.4548 - val_loss: 0.4309\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 531us/step - loss: 0.4539 - val_loss: 0.4296\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.4530 - val_loss: 0.4289\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 466us/step - loss: 0.4520 - val_loss: 0.4282\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 473us/step - loss: 0.4512 - val_loss: 0.4273\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 488us/step - loss: 0.4503 - val_loss: 0.4260\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 465us/step - loss: 0.4495 - val_loss: 0.4256\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.4486 - val_loss: 0.4249\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 464us/step - loss: 0.4476 - val_loss: 0.4244\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.4469 - val_loss: 0.4233\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 466us/step - loss: 0.4461 - val_loss: 0.4223\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 521us/step - loss: 0.4453 - val_loss: 0.4216\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 468us/step - loss: 0.4444 - val_loss: 0.4211\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 487us/step - loss: 0.4437 - val_loss: 0.4200\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 468us/step - loss: 0.4429 - val_loss: 0.4192\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.4420 - val_loss: 0.4183\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 467us/step - loss: 0.4414 - val_loss: 0.4176\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 485us/step - loss: 0.4405 - val_loss: 0.4168\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 466us/step - loss: 0.4399 - val_loss: 0.4164\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 477us/step - loss: 0.4390 - val_loss: 0.4154\n",
      "121/121 [==============================] - 0s 285us/step - loss: 0.4176\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 537us/step - loss: 3.7198 - val_loss: 1.9560\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 427us/step - loss: 1.4129 - val_loss: 0.9498\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 500us/step - loss: 0.8017 - val_loss: 0.6708\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 424us/step - loss: 0.6280 - val_loss: 0.5892\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 409us/step - loss: 0.5745 - val_loss: 0.5599\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 428us/step - loss: 0.5569 - val_loss: 0.5507\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 489us/step - loss: 0.5486 - val_loss: 0.5505\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 423us/step - loss: 0.5440 - val_loss: 0.5439\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 407us/step - loss: 0.5404 - val_loss: 0.5423\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 423us/step - loss: 0.5376 - val_loss: 0.5414\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 407us/step - loss: 0.5349 - val_loss: 0.5368\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 422us/step - loss: 0.5327 - val_loss: 0.5405\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 410us/step - loss: 0.5303 - val_loss: 0.5331\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 421us/step - loss: 0.5288 - val_loss: 0.5369\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 408us/step - loss: 0.5272 - val_loss: 0.5314\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 430us/step - loss: 0.5254 - val_loss: 0.5336\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 406us/step - loss: 0.5242 - val_loss: 0.5306\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 426us/step - loss: 0.5223 - val_loss: 0.5343\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 408us/step - loss: 0.5214 - val_loss: 0.5364\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 424us/step - loss: 0.5203 - val_loss: 0.5296\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 408us/step - loss: 0.5192 - val_loss: 0.5324\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 422us/step - loss: 0.5184 - val_loss: 0.5315\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 409us/step - loss: 0.5176 - val_loss: 0.5293\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 426us/step - loss: 0.5165 - val_loss: 0.5239\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 407us/step - loss: 0.5161 - val_loss: 0.5233\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 429us/step - loss: 0.5154 - val_loss: 0.5222\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 406us/step - loss: 0.5149 - val_loss: 0.5224\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 426us/step - loss: 0.5145 - val_loss: 0.5256\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 405us/step - loss: 0.5138 - val_loss: 0.5266\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 429us/step - loss: 0.5131 - val_loss: 0.5271\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 406us/step - loss: 0.5128 - val_loss: 0.5260\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 502us/step - loss: 0.5125 - val_loss: 0.5241\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 408us/step - loss: 0.5119 - val_loss: 0.5216\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 424us/step - loss: 0.5119 - val_loss: 0.5236\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 409us/step - loss: 0.5114 - val_loss: 0.5221\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 424us/step - loss: 0.5111 - val_loss: 0.5207\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 407us/step - loss: 0.5108 - val_loss: 0.5260\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 426us/step - loss: 0.5105 - val_loss: 0.5219\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 408us/step - loss: 0.5102 - val_loss: 0.5204\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 427us/step - loss: 0.5102 - val_loss: 0.5206\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 407us/step - loss: 0.5101 - val_loss: 0.5239\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 427us/step - loss: 0.5099 - val_loss: 0.5242\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 407us/step - loss: 0.5098 - val_loss: 0.5252\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 424us/step - loss: 0.5095 - val_loss: 0.5238\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 409us/step - loss: 0.5094 - val_loss: 0.5266\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 427us/step - loss: 0.5093 - val_loss: 0.5259\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 409us/step - loss: 0.5092 - val_loss: 0.5241\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 427us/step - loss: 0.5090 - val_loss: 0.5281\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 409us/step - loss: 0.5091 - val_loss: 0.5240\n",
      "121/121 [==============================] - 0s 264us/step - loss: 0.5483\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 534us/step - loss: 4.0982 - val_loss: 2.2922\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 406us/step - loss: 1.5921 - val_loss: 1.1688\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 427us/step - loss: 0.9722 - val_loss: 0.8570\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 405us/step - loss: 0.7956 - val_loss: 0.7570\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 434us/step - loss: 0.7341 - val_loss: 0.7128\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 411us/step - loss: 0.7049 - val_loss: 0.6862\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 505us/step - loss: 0.6853 - val_loss: 0.6663\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 407us/step - loss: 0.6695 - val_loss: 0.6488\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 423us/step - loss: 0.6558 - val_loss: 0.6337\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 409us/step - loss: 0.6434 - val_loss: 0.6202\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 533us/step - loss: 0.6322 - val_loss: 0.6083\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 410us/step - loss: 0.6220 - val_loss: 0.5974\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 426us/step - loss: 0.6129 - val_loss: 0.5879\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 408us/step - loss: 0.6044 - val_loss: 0.5789\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 422us/step - loss: 0.5970 - val_loss: 0.5712\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 409us/step - loss: 0.5901 - val_loss: 0.5642\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 421us/step - loss: 0.5839 - val_loss: 0.5578\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 405us/step - loss: 0.5784 - val_loss: 0.5524\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 420us/step - loss: 0.5733 - val_loss: 0.5478\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 408us/step - loss: 0.5685 - val_loss: 0.5428\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 424us/step - loss: 0.5644 - val_loss: 0.5389\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 408us/step - loss: 0.5606 - val_loss: 0.5350\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 425us/step - loss: 0.5573 - val_loss: 0.5323\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 406us/step - loss: 0.5541 - val_loss: 0.5293\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 424us/step - loss: 0.5511 - val_loss: 0.5262\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 409us/step - loss: 0.5488 - val_loss: 0.5244\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 421us/step - loss: 0.5464 - val_loss: 0.5230\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 406us/step - loss: 0.5443 - val_loss: 0.5216\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 424us/step - loss: 0.5424 - val_loss: 0.5195\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 407us/step - loss: 0.5406 - val_loss: 0.5184\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 426us/step - loss: 0.5391 - val_loss: 0.5167\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 406us/step - loss: 0.5377 - val_loss: 0.5154\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 424us/step - loss: 0.5363 - val_loss: 0.5147\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 402us/step - loss: 0.5351 - val_loss: 0.5135\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 423us/step - loss: 0.5341 - val_loss: 0.5140\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 412us/step - loss: 0.5332 - val_loss: 0.5128\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 426us/step - loss: 0.5323 - val_loss: 0.5126\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 405us/step - loss: 0.5315 - val_loss: 0.5123\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 424us/step - loss: 0.5308 - val_loss: 0.5118\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 407us/step - loss: 0.5301 - val_loss: 0.5107\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 422us/step - loss: 0.5295 - val_loss: 0.5112\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 407us/step - loss: 0.5290 - val_loss: 0.5114\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 429us/step - loss: 0.5285 - val_loss: 0.5094\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 410us/step - loss: 0.5281 - val_loss: 0.5088\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 426us/step - loss: 0.5276 - val_loss: 0.5103\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 409us/step - loss: 0.5274 - val_loss: 0.5101\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 423us/step - loss: 0.5271 - val_loss: 0.5099\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 406us/step - loss: 0.5267 - val_loss: 0.5101\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 421us/step - loss: 0.5264 - val_loss: 0.5095\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 408us/step - loss: 0.5262 - val_loss: 0.5098\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 426us/step - loss: 0.5259 - val_loss: 0.5102\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 406us/step - loss: 0.5257 - val_loss: 0.5111\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 428us/step - loss: 0.5256 - val_loss: 0.5106\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 406us/step - loss: 0.5253 - val_loss: 0.5112\n",
      "121/121 [==============================] - 0s 271us/step - loss: 0.5160\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 555us/step - loss: 4.7782 - val_loss: 2.7582\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 512us/step - loss: 1.9217 - val_loss: 1.3888\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 420us/step - loss: 1.1155 - val_loss: 0.9707\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 408us/step - loss: 0.8649 - val_loss: 0.8248\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 430us/step - loss: 0.7754 - val_loss: 0.7619\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 473us/step - loss: 0.7347 - val_loss: 0.7250\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 422us/step - loss: 0.7098 - val_loss: 0.6990\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 407us/step - loss: 0.6913 - val_loss: 0.6750\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 424us/step - loss: 0.6754 - val_loss: 0.6573\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 408us/step - loss: 0.6617 - val_loss: 0.6407\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 416us/step - loss: 0.6490 - val_loss: 0.6272\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 409us/step - loss: 0.6380 - val_loss: 0.6139\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 424us/step - loss: 0.6277 - val_loss: 0.6022\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 408us/step - loss: 0.6183 - val_loss: 0.5916\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 421us/step - loss: 0.6101 - val_loss: 0.5830\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 407us/step - loss: 0.6025 - val_loss: 0.5748\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 425us/step - loss: 0.5956 - val_loss: 0.5676\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 408us/step - loss: 0.5895 - val_loss: 0.5613\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 425us/step - loss: 0.5837 - val_loss: 0.5554\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 409us/step - loss: 0.5784 - val_loss: 0.5499\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 424us/step - loss: 0.5740 - val_loss: 0.5459\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 404us/step - loss: 0.5698 - val_loss: 0.5419\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 423us/step - loss: 0.5658 - val_loss: 0.5384\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 406us/step - loss: 0.5623 - val_loss: 0.5352\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 424us/step - loss: 0.5592 - val_loss: 0.5321\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 409us/step - loss: 0.5563 - val_loss: 0.5297\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 425us/step - loss: 0.5539 - val_loss: 0.5281\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 406us/step - loss: 0.5514 - val_loss: 0.5267\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 424us/step - loss: 0.5492 - val_loss: 0.5241\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 406us/step - loss: 0.5474 - val_loss: 0.5228\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 427us/step - loss: 0.5454 - val_loss: 0.5212\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 407us/step - loss: 0.5441 - val_loss: 0.5204\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 424us/step - loss: 0.5424 - val_loss: 0.5207\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 408us/step - loss: 0.5412 - val_loss: 0.5185\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 425us/step - loss: 0.5401 - val_loss: 0.5178\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 407us/step - loss: 0.5391 - val_loss: 0.5184\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 428us/step - loss: 0.5379 - val_loss: 0.5188\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 426us/step - loss: 0.5371 - val_loss: 0.5170\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 421us/step - loss: 0.5363 - val_loss: 0.5155\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 408us/step - loss: 0.5356 - val_loss: 0.5161\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 426us/step - loss: 0.5349 - val_loss: 0.5155\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 407us/step - loss: 0.5343 - val_loss: 0.5155\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 423us/step - loss: 0.5339 - val_loss: 0.5172\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 408us/step - loss: 0.5333 - val_loss: 0.5180\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 425us/step - loss: 0.5328 - val_loss: 0.5167\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 406us/step - loss: 0.5325 - val_loss: 0.5172\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 425us/step - loss: 0.5320 - val_loss: 0.5157\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 407us/step - loss: 0.5316 - val_loss: 0.5174\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 424us/step - loss: 0.5316 - val_loss: 0.5168\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 406us/step - loss: 0.5310 - val_loss: 0.5180\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 436us/step - loss: 0.5310 - val_loss: 0.5185\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 401us/step - loss: 0.5307 - val_loss: 0.5190\n",
      "121/121 [==============================] - 0s 267us/step - loss: 0.5081\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 640us/step - loss: 2.7219 - val_loss: 1.5679\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 470us/step - loss: 1.3223 - val_loss: 1.1166\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.9335 - val_loss: 0.8751\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 548us/step - loss: 0.7668 - val_loss: 0.7498\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.6918 - val_loss: 0.6906\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 465us/step - loss: 0.6518 - val_loss: 0.6568\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 0.6255 - val_loss: 0.6299\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 464us/step - loss: 0.6052 - val_loss: 0.6104\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.5881 - val_loss: 0.5914\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 464us/step - loss: 0.5724 - val_loss: 0.5744\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.5577 - val_loss: 0.5587\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 463us/step - loss: 0.5454 - val_loss: 0.5463\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.5330 - val_loss: 0.5338\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 464us/step - loss: 0.5214 - val_loss: 0.5207\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.5104 - val_loss: 0.5103\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 463us/step - loss: 0.5005 - val_loss: 0.5012\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.4911 - val_loss: 0.4888\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 466us/step - loss: 0.4827 - val_loss: 0.4808\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.4735 - val_loss: 0.4725\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 464us/step - loss: 0.4660 - val_loss: 0.4661\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.4584 - val_loss: 0.4554\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 523us/step - loss: 0.4510 - val_loss: 0.4471\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.4432 - val_loss: 0.4414\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 465us/step - loss: 0.4361 - val_loss: 0.4348\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.4304 - val_loss: 0.4291\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 468us/step - loss: 0.4250 - val_loss: 0.4212\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.4206 - val_loss: 0.4189\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 466us/step - loss: 0.4169 - val_loss: 0.4149\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 478us/step - loss: 0.4131 - val_loss: 0.4142\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 470us/step - loss: 0.4098 - val_loss: 0.4111\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 485us/step - loss: 0.4071 - val_loss: 0.4059\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 464us/step - loss: 0.4043 - val_loss: 0.4032\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 0.4020 - val_loss: 0.4039\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 464us/step - loss: 0.3992 - val_loss: 0.3999\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 0.3973 - val_loss: 0.3970\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 466us/step - loss: 0.3955 - val_loss: 0.3949\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.3919 - val_loss: 0.3955\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 466us/step - loss: 0.3910 - val_loss: 0.3962\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 0.3886 - val_loss: 0.3902\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 465us/step - loss: 0.3871 - val_loss: 0.3904\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 0.3851 - val_loss: 0.3877\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 471us/step - loss: 0.3836 - val_loss: 0.3907\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.3816 - val_loss: 0.3854\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 465us/step - loss: 0.3801 - val_loss: 0.3880\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 0.3786 - val_loss: 0.3892\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 465us/step - loss: 0.3773 - val_loss: 0.3799\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.3759 - val_loss: 0.3798\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 465us/step - loss: 0.3740 - val_loss: 0.3766\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.3724 - val_loss: 0.3792\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 463us/step - loss: 0.3708 - val_loss: 0.3746\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.3701 - val_loss: 0.3735\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 531us/step - loss: 0.3690 - val_loss: 0.3761\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.3682 - val_loss: 0.3737\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 465us/step - loss: 0.3659 - val_loss: 0.3715\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 0.3650 - val_loss: 0.3693\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 466us/step - loss: 0.3634 - val_loss: 0.3687\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 488us/step - loss: 0.3616 - val_loss: 0.3680\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 467us/step - loss: 0.3609 - val_loss: 0.3666\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.3596 - val_loss: 0.3735\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 465us/step - loss: 0.3589 - val_loss: 0.3660\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 0.3574 - val_loss: 0.3641\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 465us/step - loss: 0.3565 - val_loss: 0.3646\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.3554 - val_loss: 0.3662\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 563us/step - loss: 0.3544 - val_loss: 0.3621\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 488us/step - loss: 0.3533 - val_loss: 0.3589\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 464us/step - loss: 0.3521 - val_loss: 0.3635\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.3513 - val_loss: 0.3581\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 462us/step - loss: 0.3498 - val_loss: 0.3573\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.3487 - val_loss: 0.3555\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 465us/step - loss: 0.3483 - val_loss: 0.3578\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.3470 - val_loss: 0.3556\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 465us/step - loss: 0.3460 - val_loss: 0.3526\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.3455 - val_loss: 0.3532\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 463us/step - loss: 0.3446 - val_loss: 0.3528\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.3432 - val_loss: 0.3506\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 466us/step - loss: 0.3423 - val_loss: 0.3503\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.3417 - val_loss: 0.3490\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 466us/step - loss: 0.3406 - val_loss: 0.3490\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 490us/step - loss: 0.3401 - val_loss: 0.3475\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 464us/step - loss: 0.3388 - val_loss: 0.3511\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.3380 - val_loss: 0.3504\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 467us/step - loss: 0.3378 - val_loss: 0.3474\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 488us/step - loss: 0.3372 - val_loss: 0.3447\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 467us/step - loss: 0.3355 - val_loss: 0.3462\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.3346 - val_loss: 0.3492\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 462us/step - loss: 0.3344 - val_loss: 0.3469\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.3334 - val_loss: 0.3422\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 463us/step - loss: 0.3328 - val_loss: 0.3432\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.3322 - val_loss: 0.3428\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 465us/step - loss: 0.3313 - val_loss: 0.3415\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 0.3304 - val_loss: 0.3409\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 467us/step - loss: 0.3300 - val_loss: 0.3421\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 0.3293 - val_loss: 0.3423\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 465us/step - loss: 0.3288 - val_loss: 0.3396\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.3280 - val_loss: 0.3395\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 464us/step - loss: 0.3270 - val_loss: 0.3379\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.3269 - val_loss: 0.3367\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 463us/step - loss: 0.3260 - val_loss: 0.3369\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 539us/step - loss: 0.3254 - val_loss: 0.3409\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 465us/step - loss: 0.3254 - val_loss: 0.3353\n",
      "121/121 [==============================] - 0s 278us/step - loss: 0.3675\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 648us/step - loss: 2.8090 - val_loss: 1.6035\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 468us/step - loss: 1.2503 - val_loss: 1.0221\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 0.8797 - val_loss: 0.7865\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 466us/step - loss: 0.7183 - val_loss: 0.6730\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 0.6479 - val_loss: 0.6263\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 467us/step - loss: 0.6171 - val_loss: 0.6016\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.5984 - val_loss: 0.5839\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 465us/step - loss: 0.5835 - val_loss: 0.5690\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 0.5705 - val_loss: 0.5555\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 467us/step - loss: 0.5580 - val_loss: 0.5438\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.5468 - val_loss: 0.5330\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 463us/step - loss: 0.5360 - val_loss: 0.5213\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 0.5263 - val_loss: 0.5121\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 468us/step - loss: 0.5168 - val_loss: 0.5022\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 486us/step - loss: 0.5086 - val_loss: 0.4939\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 463us/step - loss: 0.5006 - val_loss: 0.4865\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.4935 - val_loss: 0.4788\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 460us/step - loss: 0.4871 - val_loss: 0.4723\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.4809 - val_loss: 0.4678\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 465us/step - loss: 0.4752 - val_loss: 0.4629\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 475us/step - loss: 0.4705 - val_loss: 0.4578\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 467us/step - loss: 0.4657 - val_loss: 0.4523\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 0.4615 - val_loss: 0.4480\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 468us/step - loss: 0.4575 - val_loss: 0.4444\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.4539 - val_loss: 0.4411\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 569us/step - loss: 0.4497 - val_loss: 0.4382\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 487us/step - loss: 0.4467 - val_loss: 0.4340\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 498us/step - loss: 0.4442 - val_loss: 0.4319\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 465us/step - loss: 0.4402 - val_loss: 0.4289\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.4375 - val_loss: 0.4263\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.4347 - val_loss: 0.4239\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 465us/step - loss: 0.4321 - val_loss: 0.4220\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 485us/step - loss: 0.4295 - val_loss: 0.4200\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 487us/step - loss: 0.4269 - val_loss: 0.4167\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 467us/step - loss: 0.4246 - val_loss: 0.4141\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.4222 - val_loss: 0.4123\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.4198 - val_loss: 0.4097\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 468us/step - loss: 0.4176 - val_loss: 0.4090\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.4156 - val_loss: 0.4066\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.4138 - val_loss: 0.4048\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 461us/step - loss: 0.4113 - val_loss: 0.4034\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 485us/step - loss: 0.4097 - val_loss: 0.4013\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.4076 - val_loss: 0.3989\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 466us/step - loss: 0.4058 - val_loss: 0.3980\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.4043 - val_loss: 0.3960\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 567us/step - loss: 0.4025 - val_loss: 0.3943\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.4006 - val_loss: 0.3947\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 465us/step - loss: 0.3992 - val_loss: 0.3919\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 0.3975 - val_loss: 0.3898\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 464us/step - loss: 0.3963 - val_loss: 0.3884\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 0.3945 - val_loss: 0.3878\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.3927 - val_loss: 0.3851\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 466us/step - loss: 0.3917 - val_loss: 0.3841\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 0.3900 - val_loss: 0.3833\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.3888 - val_loss: 0.3810\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 468us/step - loss: 0.3873 - val_loss: 0.3805\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.3858 - val_loss: 0.3785\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.3844 - val_loss: 0.3780\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 463us/step - loss: 0.3830 - val_loss: 0.3788\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 476us/step - loss: 0.3819 - val_loss: 0.3760\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.3808 - val_loss: 0.3746\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 465us/step - loss: 0.3794 - val_loss: 0.3742\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.3783 - val_loss: 0.3732\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 463us/step - loss: 0.3774 - val_loss: 0.3729\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 486us/step - loss: 0.3759 - val_loss: 0.3709\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.3748 - val_loss: 0.3698\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 462us/step - loss: 0.3741 - val_loss: 0.3688\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 0.3729 - val_loss: 0.3684\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 485us/step - loss: 0.3714 - val_loss: 0.3679\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 467us/step - loss: 0.3707 - val_loss: 0.3664\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 589us/step - loss: 0.3699 - val_loss: 0.3667\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.3687 - val_loss: 0.3646\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 477us/step - loss: 0.3676 - val_loss: 0.3656\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 469us/step - loss: 0.3671 - val_loss: 0.3630\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.3654 - val_loss: 0.3618\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.3650 - val_loss: 0.3620\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 463us/step - loss: 0.3641 - val_loss: 0.3616\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.3637 - val_loss: 0.3614\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 0.3625 - val_loss: 0.3595\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 466us/step - loss: 0.3619 - val_loss: 0.3588\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 485us/step - loss: 0.3605 - val_loss: 0.3579\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 465us/step - loss: 0.3596 - val_loss: 0.3580\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 489us/step - loss: 0.3594 - val_loss: 0.3570\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 0.3579 - val_loss: 0.3581\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 463us/step - loss: 0.3575 - val_loss: 0.3551\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.3568 - val_loss: 0.3556\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 526us/step - loss: 0.3559 - val_loss: 0.3558\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 478us/step - loss: 0.3555 - val_loss: 0.3552\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 467us/step - loss: 0.3547 - val_loss: 0.3533\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.3540 - val_loss: 0.3527\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 463us/step - loss: 0.3526 - val_loss: 0.3518\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.3526 - val_loss: 0.3513\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 464us/step - loss: 0.3518 - val_loss: 0.3504\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 549us/step - loss: 0.3508 - val_loss: 0.3517\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 465us/step - loss: 0.3498 - val_loss: 0.3514\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 485us/step - loss: 0.3500 - val_loss: 0.3489\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.3491 - val_loss: 0.3482\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 466us/step - loss: 0.3475 - val_loss: 0.3499\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.3481 - val_loss: 0.3473\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 465us/step - loss: 0.3472 - val_loss: 0.3478\n",
      "121/121 [==============================] - 0s 318us/step - loss: 0.3639\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 633us/step - loss: 1.8424 - val_loss: 0.9914\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.8585 - val_loss: 0.7721\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 466us/step - loss: 0.7456 - val_loss: 0.7010\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.7006 - val_loss: 0.6615\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 463us/step - loss: 0.6690 - val_loss: 0.6316\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.6421 - val_loss: 0.6073\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.6203 - val_loss: 0.5860\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 465us/step - loss: 0.6002 - val_loss: 0.5684\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 485us/step - loss: 0.5835 - val_loss: 0.5512\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 465us/step - loss: 0.5686 - val_loss: 0.5354\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 485us/step - loss: 0.5543 - val_loss: 0.5219\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 466us/step - loss: 0.5416 - val_loss: 0.5089\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.5306 - val_loss: 0.4974\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 469us/step - loss: 0.5201 - val_loss: 0.4867\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.5109 - val_loss: 0.4802\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.5029 - val_loss: 0.4696\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 534us/step - loss: 0.4953 - val_loss: 0.4627\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 0.4875 - val_loss: 0.4571\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 462us/step - loss: 0.4816 - val_loss: 0.4503\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.4753 - val_loss: 0.4474\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 555us/step - loss: 0.4710 - val_loss: 0.4382\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.4652 - val_loss: 0.4326\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 468us/step - loss: 0.4607 - val_loss: 0.4295\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.4563 - val_loss: 0.4236\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.4521 - val_loss: 0.4212\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 466us/step - loss: 0.4477 - val_loss: 0.4169\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 486us/step - loss: 0.4448 - val_loss: 0.4132\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 465us/step - loss: 0.4409 - val_loss: 0.4115\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 0.4379 - val_loss: 0.4064\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 485us/step - loss: 0.4350 - val_loss: 0.4037\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 465us/step - loss: 0.4316 - val_loss: 0.4017\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 487us/step - loss: 0.4292 - val_loss: 0.3976\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 478us/step - loss: 0.4266 - val_loss: 0.3944\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 467us/step - loss: 0.4234 - val_loss: 0.3942\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.4211 - val_loss: 0.3914\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 0.4196 - val_loss: 0.3878\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 465us/step - loss: 0.4164 - val_loss: 0.3906\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 489us/step - loss: 0.4152 - val_loss: 0.3836\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 467us/step - loss: 0.4121 - val_loss: 0.3831\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.4103 - val_loss: 0.3805\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 465us/step - loss: 0.4088 - val_loss: 0.3784\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 0.4061 - val_loss: 0.3774\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 466us/step - loss: 0.4052 - val_loss: 0.3745\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 488us/step - loss: 0.4025 - val_loss: 0.3740\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 462us/step - loss: 0.4014 - val_loss: 0.3717\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.3997 - val_loss: 0.3694\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 464us/step - loss: 0.3976 - val_loss: 0.3703\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.3963 - val_loss: 0.3675\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 467us/step - loss: 0.3947 - val_loss: 0.3672\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 0.3927 - val_loss: 0.3643\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 464us/step - loss: 0.3918 - val_loss: 0.3635\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.3900 - val_loss: 0.3634\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 540us/step - loss: 0.3884 - val_loss: 0.3613\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 486us/step - loss: 0.3871 - val_loss: 0.3597\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 0.3853 - val_loss: 0.3584\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 0.3848 - val_loss: 0.3566\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.3825 - val_loss: 0.3557\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 488us/step - loss: 0.3813 - val_loss: 0.3549\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.3803 - val_loss: 0.3528\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 462us/step - loss: 0.3787 - val_loss: 0.3534\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 486us/step - loss: 0.3775 - val_loss: 0.3515\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.3762 - val_loss: 0.3500\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.3746 - val_loss: 0.3492\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 485us/step - loss: 0.3737 - val_loss: 0.3467\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 464us/step - loss: 0.3724 - val_loss: 0.3465\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.3714 - val_loss: 0.3471\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.3699 - val_loss: 0.3460\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 0.3682 - val_loss: 0.3443\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.3674 - val_loss: 0.3442\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 493us/step - loss: 0.3658 - val_loss: 0.3432\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.3649 - val_loss: 0.3426\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.3638 - val_loss: 0.3428\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 0.3628 - val_loss: 0.3405\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 486us/step - loss: 0.3615 - val_loss: 0.3399\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 593us/step - loss: 0.3603 - val_loss: 0.3384\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 0.3597 - val_loss: 0.3397\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 478us/step - loss: 0.3584 - val_loss: 0.3376\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.3569 - val_loss: 0.3389\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 0.3567 - val_loss: 0.3361\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 509us/step - loss: 0.3559 - val_loss: 0.3347\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 488us/step - loss: 0.3550 - val_loss: 0.3346\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 468us/step - loss: 0.3533 - val_loss: 0.3349\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.3535 - val_loss: 0.3351\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.3524 - val_loss: 0.3331\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.3517 - val_loss: 0.3324\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 481us/step - loss: 0.3504 - val_loss: 0.3314\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.3497 - val_loss: 0.3312\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 480us/step - loss: 0.3479 - val_loss: 0.3310\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 493us/step - loss: 0.3479 - val_loss: 0.3309\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 491us/step - loss: 0.3471 - val_loss: 0.3317\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 487us/step - loss: 0.3458 - val_loss: 0.3315\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 553us/step - loss: 0.3455 - val_loss: 0.3305\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.3442 - val_loss: 0.3285\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.3433 - val_loss: 0.3310\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 484us/step - loss: 0.3434 - val_loss: 0.3278\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 463us/step - loss: 0.3418 - val_loss: 0.3288\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 0.3416 - val_loss: 0.3268\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 482us/step - loss: 0.3406 - val_loss: 0.3258\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 479us/step - loss: 0.3398 - val_loss: 0.3265\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 478us/step - loss: 0.3388 - val_loss: 0.3276\n",
      "121/121 [==============================] - 0s 283us/step - loss: 0.3334\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 570us/step - loss: 1.5636 - val_loss: 0.8208\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 0.9456 - val_loss: 0.5165\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 443us/step - loss: 0.4892 - val_loss: 0.4634\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 0.4581 - val_loss: 0.4379\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.4431 - val_loss: 0.4140\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 443us/step - loss: 0.4240 - val_loss: 0.4087\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.4124 - val_loss: 0.4259\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 443us/step - loss: 0.4188 - val_loss: 0.3891\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 442us/step - loss: 0.4052 - val_loss: 0.3924\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 0.4017 - val_loss: 0.3958\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 441us/step - loss: 0.4039 - val_loss: 0.4233\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.3995 - val_loss: 0.4175\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 442us/step - loss: 0.3988 - val_loss: 0.3938\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 533us/step - loss: 0.3979 - val_loss: 0.3833\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 439us/step - loss: 0.3936 - val_loss: 0.3863\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 442us/step - loss: 0.4007 - val_loss: 0.3815\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 441us/step - loss: 0.3949 - val_loss: 0.3782\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 432us/step - loss: 0.3919 - val_loss: 0.3911\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 432us/step - loss: 0.3939 - val_loss: 0.3865\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 432us/step - loss: 0.3914 - val_loss: 0.3759\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 590us/step - loss: 0.3918 - val_loss: 0.3827\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.3922 - val_loss: 0.3845\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 439us/step - loss: 0.3967 - val_loss: 0.3813\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 440us/step - loss: 0.3899 - val_loss: 0.3727\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 432us/step - loss: 0.3957 - val_loss: 0.3767\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 432us/step - loss: 0.3926 - val_loss: 0.3758\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 432us/step - loss: 0.3897 - val_loss: 0.3832\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 432us/step - loss: 0.3894 - val_loss: 0.3802\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 431us/step - loss: 0.3896 - val_loss: 0.3767\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 425us/step - loss: 0.3888 - val_loss: 0.3787\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 0.3891 - val_loss: 0.3854\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 556us/step - loss: 0.3874 - val_loss: 0.3705\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 499us/step - loss: 0.3886 - val_loss: 0.3803\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.3886 - val_loss: 0.3698\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 442us/step - loss: 0.3891 - val_loss: 0.3736\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 428us/step - loss: 0.3880 - val_loss: 0.3951\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 453us/step - loss: 0.3874 - val_loss: 0.3771\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 431us/step - loss: 0.3856 - val_loss: 0.3698\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 438us/step - loss: 0.3884 - val_loss: 0.3720\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 449us/step - loss: 0.3842 - val_loss: 0.3691\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 442us/step - loss: 0.3837 - val_loss: 0.3769\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 518us/step - loss: 0.3858 - val_loss: 0.3782\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.3931 - val_loss: 0.3882\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 438us/step - loss: 0.3848 - val_loss: 0.3715\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 440us/step - loss: 0.3863 - val_loss: 0.3692\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 524us/step - loss: 0.3847 - val_loss: 0.3691\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 0.3886 - val_loss: 0.3752\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 509us/step - loss: 0.3888 - val_loss: 0.3651\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 562us/step - loss: 0.3864 - val_loss: 0.3658\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 440us/step - loss: 0.3820 - val_loss: 0.3738\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 450us/step - loss: 0.3806 - val_loss: 0.3740\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 494us/step - loss: 0.3823 - val_loss: 0.3851\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 442us/step - loss: 0.4115 - val_loss: 0.3757\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 430us/step - loss: 0.3877 - val_loss: 0.3775\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 433us/step - loss: 0.3839 - val_loss: 0.3698\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 436us/step - loss: 0.3902 - val_loss: 0.3631\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 432us/step - loss: 0.3823 - val_loss: 0.3851\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 432us/step - loss: 0.3876 - val_loss: 0.3634\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 531us/step - loss: 0.3845 - val_loss: 0.3794\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 441us/step - loss: 0.3811 - val_loss: 0.5211\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 436us/step - loss: 0.3863 - val_loss: 0.3651\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 428us/step - loss: 0.3779 - val_loss: 0.3699\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 451us/step - loss: 0.3793 - val_loss: 0.3667\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 442us/step - loss: 0.3839 - val_loss: 0.3995\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 431us/step - loss: 0.3828 - val_loss: 0.3737\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 434us/step - loss: 0.3771 - val_loss: 0.3640\n",
      "121/121 [==============================] - 0s 277us/step - loss: 0.4134\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 575us/step - loss: 1.0148 - val_loss: 0.6778\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.6651 - val_loss: 0.5357\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 441us/step - loss: 0.5202 - val_loss: 0.4748\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 439us/step - loss: 0.4788 - val_loss: 0.4480\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 433us/step - loss: 0.4586 - val_loss: 0.4250\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 433us/step - loss: 0.4482 - val_loss: 0.4184\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 437us/step - loss: 0.4419 - val_loss: 0.4139\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 433us/step - loss: 0.4369 - val_loss: 0.4072\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 431us/step - loss: 0.4313 - val_loss: 0.4085\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 431us/step - loss: 0.4301 - val_loss: 0.3988\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 432us/step - loss: 0.4257 - val_loss: 0.4138\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 434us/step - loss: 0.4240 - val_loss: 0.3997\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 432us/step - loss: 0.4222 - val_loss: 0.4005\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 515us/step - loss: 0.4213 - val_loss: 0.3953\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 542us/step - loss: 0.4197 - val_loss: 0.3939\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 433us/step - loss: 0.4183 - val_loss: 0.3924\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 433us/step - loss: 0.4175 - val_loss: 0.3878\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 539us/step - loss: 0.4162 - val_loss: 0.3865\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 434us/step - loss: 0.4149 - val_loss: 0.3873\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 434us/step - loss: 0.4144 - val_loss: 0.3850\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 433us/step - loss: 0.4127 - val_loss: 0.3857\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 425us/step - loss: 0.4126 - val_loss: 0.3874\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 0.4109 - val_loss: 0.3907\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.4103 - val_loss: 0.3839\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.4079 - val_loss: 0.3906\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 443us/step - loss: 0.4086 - val_loss: 0.3833\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.4077 - val_loss: 0.3785\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 443us/step - loss: 0.4063 - val_loss: 0.3806\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 0.4053 - val_loss: 0.3747\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.4046 - val_loss: 0.3784\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 542us/step - loss: 0.4029 - val_loss: 0.3726\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 450us/step - loss: 0.4030 - val_loss: 0.3720\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.4025 - val_loss: 0.3714\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.4013 - val_loss: 0.3733\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.4012 - val_loss: 0.3708\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 0.3998 - val_loss: 0.3721\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 0.3997 - val_loss: 0.3700\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 452us/step - loss: 0.3986 - val_loss: 0.3689\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 0.3989 - val_loss: 0.3728\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.3979 - val_loss: 0.3700\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.3990 - val_loss: 0.3662\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 545us/step - loss: 0.3977 - val_loss: 0.3676\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 432us/step - loss: 0.3968 - val_loss: 0.3686\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 432us/step - loss: 0.3961 - val_loss: 0.3691\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 433us/step - loss: 0.3963 - val_loss: 0.3703\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 434us/step - loss: 0.3959 - val_loss: 0.3654\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 432us/step - loss: 0.3959 - val_loss: 0.3636\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 434us/step - loss: 0.3941 - val_loss: 0.3643\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 432us/step - loss: 0.3948 - val_loss: 0.3662\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 511us/step - loss: 0.3931 - val_loss: 0.3640\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 434us/step - loss: 0.3927 - val_loss: 0.3673\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 432us/step - loss: 0.3936 - val_loss: 0.3637\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 431us/step - loss: 0.3932 - val_loss: 0.3607\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 437us/step - loss: 0.3930 - val_loss: 0.3624\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 432us/step - loss: 0.3921 - val_loss: 0.3671\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 671us/step - loss: 0.3916 - val_loss: 0.3620\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 435us/step - loss: 0.3907 - val_loss: 0.3596\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 449us/step - loss: 0.3907 - val_loss: 0.3579\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 435us/step - loss: 0.3902 - val_loss: 0.3624\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 434us/step - loss: 0.3903 - val_loss: 0.3629\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 432us/step - loss: 0.3908 - val_loss: 0.3600\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 433us/step - loss: 0.3896 - val_loss: 0.3658\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 433us/step - loss: 0.3897 - val_loss: 0.3631\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 424us/step - loss: 0.3896 - val_loss: 0.3618\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 453us/step - loss: 0.3887 - val_loss: 0.3609\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 436us/step - loss: 0.3886 - val_loss: 0.3598\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 428us/step - loss: 0.3884 - val_loss: 0.3677\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.3888 - val_loss: 0.3574\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 525us/step - loss: 0.3875 - val_loss: 0.3623\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 425us/step - loss: 0.3876 - val_loss: 0.3597\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 512us/step - loss: 0.3887 - val_loss: 0.3616\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 427us/step - loss: 0.3882 - val_loss: 0.3584\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.3876 - val_loss: 0.3625\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 423us/step - loss: 0.3866 - val_loss: 0.3718\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 455us/step - loss: 0.3868 - val_loss: 0.3586\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 431us/step - loss: 0.3872 - val_loss: 0.3566\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 426us/step - loss: 0.3875 - val_loss: 0.3558\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 0.3868 - val_loss: 0.3603\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 432us/step - loss: 0.3849 - val_loss: 0.3626\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 427us/step - loss: 0.3860 - val_loss: 0.3628\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 449us/step - loss: 0.3856 - val_loss: 0.3595\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 431us/step - loss: 0.3851 - val_loss: 0.3584\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 427us/step - loss: 0.3848 - val_loss: 0.3565\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 558us/step - loss: 0.3848 - val_loss: 0.3573\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 434us/step - loss: 0.3845 - val_loss: 0.3540\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.3849 - val_loss: 0.3586\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 434us/step - loss: 0.3841 - val_loss: 0.3556\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 424us/step - loss: 0.3828 - val_loss: 0.3546\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 453us/step - loss: 0.3830 - val_loss: 0.3556\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 0.3828 - val_loss: 0.3582\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 428us/step - loss: 0.3838 - val_loss: 0.3617\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 0.3837 - val_loss: 0.3539\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 435us/step - loss: 0.3829 - val_loss: 0.3627\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 427us/step - loss: 0.3827 - val_loss: 0.3585\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 460us/step - loss: 0.3834 - val_loss: 0.3601\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.3827 - val_loss: 0.3540\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 433us/step - loss: 0.3828 - val_loss: 0.3538\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 425us/step - loss: 0.3818 - val_loss: 0.3561\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 568us/step - loss: 0.3826 - val_loss: 0.3532\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 508us/step - loss: 0.3816 - val_loss: 0.3550\n",
      "121/121 [==============================] - 0s 268us/step - loss: 0.3863\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 572us/step - loss: 1.3794 - val_loss: 0.6515\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 449us/step - loss: 0.7452 - val_loss: 0.9731\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 1.8571 - val_loss: 0.5426\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 433us/step - loss: 0.5184 - val_loss: 0.4673\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 427us/step - loss: 0.4825 - val_loss: 0.4670\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 451us/step - loss: 0.4669 - val_loss: 0.4279\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 432us/step - loss: 0.4579 - val_loss: 0.4361\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 524us/step - loss: 0.4497 - val_loss: 0.4132\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 459us/step - loss: 0.7064 - val_loss: 0.9547\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 435us/step - loss: 0.6401 - val_loss: 0.4408\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 423us/step - loss: 0.4815 - val_loss: 0.4176\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 447us/step - loss: 0.4659 - val_loss: 0.4231\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 434us/step - loss: 0.4520 - val_loss: 0.4153\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 425us/step - loss: 0.4455 - val_loss: 0.4115\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 449us/step - loss: 0.4405 - val_loss: 0.4040\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 431us/step - loss: 0.4377 - val_loss: 0.3973\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 424us/step - loss: 0.4341 - val_loss: 0.3982\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.4290 - val_loss: 0.3995\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 429us/step - loss: 0.4269 - val_loss: 0.3981\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 455us/step - loss: 0.4236 - val_loss: 0.3903\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 428us/step - loss: 0.4282 - val_loss: 0.5015\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 483us/step - loss: 0.4270 - val_loss: 0.3926\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 428us/step - loss: 0.4241 - val_loss: 0.5357\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 450us/step - loss: 0.4181 - val_loss: 0.3864\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 425us/step - loss: 0.4159 - val_loss: 0.3870\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 450us/step - loss: 0.4151 - val_loss: 0.3958\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 556us/step - loss: 0.4142 - val_loss: 0.4605\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.4101 - val_loss: 0.3835\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 455us/step - loss: 0.4189 - val_loss: 0.3935\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.4198 - val_loss: 0.3820\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.4100 - val_loss: 0.3835\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 0.4094 - val_loss: 0.3857\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 0.4071 - val_loss: 0.3852\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 529us/step - loss: 0.4042 - val_loss: 0.3912\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 449us/step - loss: 0.4030 - val_loss: 0.3778\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 438us/step - loss: 0.4021 - val_loss: 0.3870\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.4007 - val_loss: 0.3829\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 440us/step - loss: 0.4018 - val_loss: 0.3768\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 443us/step - loss: 0.4004 - val_loss: 0.3872\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 442us/step - loss: 0.3992 - val_loss: 0.3773\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 448us/step - loss: 0.4056 - val_loss: 0.3744\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 450us/step - loss: 0.3993 - val_loss: 0.3781\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 443us/step - loss: 0.3986 - val_loss: 0.3757\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 546us/step - loss: 0.3983 - val_loss: 0.3815\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 0.3975 - val_loss: 0.3721\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.3975 - val_loss: 0.3777\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.3944 - val_loss: 0.3727\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.3968 - val_loss: 0.3744\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 445us/step - loss: 0.3967 - val_loss: 0.3797\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 438us/step - loss: 0.3952 - val_loss: 0.3998\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 442us/step - loss: 0.4002 - val_loss: 0.3738\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.3979 - val_loss: 0.3779\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 446us/step - loss: 0.3979 - val_loss: 0.3749\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 0.3961 - val_loss: 0.3763\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 444us/step - loss: 0.3944 - val_loss: 0.3766\n",
      "121/121 [==============================] - 0s 270us/step - loss: 0.3794\n",
      "Epoch 1/100\n",
      "363/363 [==============================] - 0s 529us/step - loss: 0.7763 - val_loss: 0.5128\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 0s 427us/step - loss: 0.4805 - val_loss: 0.4179\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 0s 419us/step - loss: 0.4323 - val_loss: 0.3922\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 0s 502us/step - loss: 0.4140 - val_loss: 0.3821\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 0s 419us/step - loss: 0.4048 - val_loss: 0.3722\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 0s 424us/step - loss: 0.3943 - val_loss: 0.3806\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 0s 419us/step - loss: 0.3903 - val_loss: 0.3606\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 0s 419us/step - loss: 0.3836 - val_loss: 0.3626\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 0s 421us/step - loss: 0.3774 - val_loss: 0.3589\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 0s 421us/step - loss: 0.3739 - val_loss: 0.3455\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 0s 420us/step - loss: 0.3708 - val_loss: 0.3480\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 0s 421us/step - loss: 0.3682 - val_loss: 0.3473\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 0s 421us/step - loss: 0.3652 - val_loss: 0.3445\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 0s 419us/step - loss: 0.3621 - val_loss: 0.3418\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 0s 487us/step - loss: 0.3609 - val_loss: 0.3360\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 0s 420us/step - loss: 0.3589 - val_loss: 0.3546\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 0s 418us/step - loss: 0.3577 - val_loss: 0.3375\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 0s 466us/step - loss: 0.3573 - val_loss: 0.3355\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 0s 420us/step - loss: 0.3562 - val_loss: 0.3343\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 0s 418us/step - loss: 0.3532 - val_loss: 0.3425\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 0s 479us/step - loss: 0.3506 - val_loss: 0.3307\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 0s 419us/step - loss: 0.3475 - val_loss: 0.3234\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 0s 419us/step - loss: 0.3474 - val_loss: 0.3280\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 0s 419us/step - loss: 0.3456 - val_loss: 0.3383\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 0s 419us/step - loss: 0.3441 - val_loss: 0.3265\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 0s 416us/step - loss: 0.3431 - val_loss: 0.3246\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 0s 423us/step - loss: 0.3407 - val_loss: 0.3338\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 0s 483us/step - loss: 0.3394 - val_loss: 0.3146\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 0s 418us/step - loss: 0.3366 - val_loss: 0.3183\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 0s 419us/step - loss: 0.3371 - val_loss: 0.3165\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 0s 419us/step - loss: 0.3361 - val_loss: 0.3170\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 0s 423us/step - loss: 0.3352 - val_loss: 0.3107\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 0s 468us/step - loss: 0.3354 - val_loss: 0.3142\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 0s 415us/step - loss: 0.3312 - val_loss: 0.3156\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 0s 420us/step - loss: 0.3311 - val_loss: 0.3104\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 0s 422us/step - loss: 0.3290 - val_loss: 0.3242\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 0s 421us/step - loss: 0.3289 - val_loss: 0.3103\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 0s 422us/step - loss: 0.3282 - val_loss: 0.3076\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 0s 487us/step - loss: 0.3262 - val_loss: 0.3202\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 0s 418us/step - loss: 0.3257 - val_loss: 0.3129\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 0s 420us/step - loss: 0.3244 - val_loss: 0.3174\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 0s 421us/step - loss: 0.3251 - val_loss: 0.3378\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 0s 424us/step - loss: 0.3225 - val_loss: 0.3059\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 0s 470us/step - loss: 0.3221 - val_loss: 0.3036\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 0s 422us/step - loss: 0.3206 - val_loss: 0.3093\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 0s 420us/step - loss: 0.3206 - val_loss: 0.2995\n",
      "Epoch 47/100\n",
      "363/363 [==============================] - 0s 420us/step - loss: 0.3179 - val_loss: 0.3047\n",
      "Epoch 48/100\n",
      "363/363 [==============================] - 0s 419us/step - loss: 0.3182 - val_loss: 0.3286\n",
      "Epoch 49/100\n",
      "363/363 [==============================] - 0s 420us/step - loss: 0.3175 - val_loss: 0.3276\n",
      "Epoch 50/100\n",
      "363/363 [==============================] - 0s 422us/step - loss: 0.3166 - val_loss: 0.3106\n",
      "Epoch 51/100\n",
      "363/363 [==============================] - 0s 483us/step - loss: 0.3245 - val_loss: 0.3042\n",
      "Epoch 52/100\n",
      "363/363 [==============================] - 0s 558us/step - loss: 0.3184 - val_loss: 0.3211\n",
      "Epoch 53/100\n",
      "363/363 [==============================] - 0s 424us/step - loss: 0.3169 - val_loss: 0.3110\n",
      "Epoch 54/100\n",
      "363/363 [==============================] - 0s 426us/step - loss: 0.3153 - val_loss: 0.3046\n",
      "Epoch 55/100\n",
      "363/363 [==============================] - 0s 422us/step - loss: 0.3138 - val_loss: 0.3014\n",
      "Epoch 56/100\n",
      "363/363 [==============================] - 0s 420us/step - loss: 0.3147 - val_loss: 0.3029\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=3,\n",
       "                   estimator=&lt;keras.wrappers.scikit_learn.KerasRegressor object at 0x136cfb580&gt;,\n",
       "                   param_distributions={&#x27;learning_rate&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x1376a01f0&gt;,\n",
       "                                        &#x27;n_hidden&#x27;: [0, 1, 2, 3],\n",
       "                                        &#x27;n_neurons&#x27;: array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
       "       35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51,\n",
       "       52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68,\n",
       "       69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85,\n",
       "       86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99])})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=3,\n",
       "                   estimator=&lt;keras.wrappers.scikit_learn.KerasRegressor object at 0x136cfb580&gt;,\n",
       "                   param_distributions={&#x27;learning_rate&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x1376a01f0&gt;,\n",
       "                                        &#x27;n_hidden&#x27;: [0, 1, 2, 3],\n",
       "                                        &#x27;n_neurons&#x27;: array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
       "       35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51,\n",
       "       52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68,\n",
       "       69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85,\n",
       "       86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99])})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: KerasRegressor</label><div class=\"sk-toggleable__content\"><pre>&lt;keras.wrappers.scikit_learn.KerasRegressor object at 0x136cfb580&gt;</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KerasRegressor</label><div class=\"sk-toggleable__content\"><pre>&lt;keras.wrappers.scikit_learn.KerasRegressor object at 0x136cfb580&gt;</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=<keras.wrappers.scikit_learn.KerasRegressor object at 0x136cfb580>,\n",
       "                   param_distributions={'learning_rate': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x1376a01f0>,\n",
       "                                        'n_hidden': [0, 1, 2, 3],\n",
       "                                        'n_neurons': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
       "       35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51,\n",
       "       52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68,\n",
       "       69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85,\n",
       "       86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99])})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_distribs = {\n",
    "\"n_hidden\": [0, 1, 2, 3],\n",
    "\"n_neurons\": np.arange(1, 100),\n",
    "\"learning_rate\": reciprocal(3e-4, 3e-2),\n",
    "}\n",
    "\n",
    "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=10, cv=3)\n",
    "rnd_search_cv.fit(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    epochs=100,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    callbacks=[keras.callbacks.EarlyStopping(patience=10)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.010243512177571289, 'n_hidden': 3, 'n_neurons': 12}\n",
      "-0.32605581482251483\n"
     ]
    }
   ],
   "source": [
    "print(rnd_search_cv.best_params_)\n",
    "print(rnd_search_cv.best_score_)\n",
    "model = rnd_search_cv.best_estimator_.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rule of thumbs for \n",
    "1. Number of hidden layers\n",
    "2. Number of Neurons\n",
    "3. Learning rates, batch size and other hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Number of hidden layers:\n",
    "    For most of the simple problem, it is sufficient to have one or two hidden layers\n",
    "    For more complex problem, more layers are needed. You can try to increase the number of layers up until it starts to overfit.\n",
    "    For a more complex problem such as image recognition and speech recognition, you rarely have to train from scratch. It is much more common to reuse the part of pretrained part of the pre-trained state of the art network.\n",
    "\n",
    "2. Number of Neurons per hidden layer:\n",
    "    The number of Neurons for the input and output layer is decided by input data's shape and type of the task.\n",
    "    It used to be common to size the number of neurons in hidden layers in pyramid shape. However, this practice has been abandoned because the same number of neurons per hidden layer seems to perform as good as having a pyramid shape. And this has an advantage that you have only one hyperparameter to tune rather than each per hidden layer.\n",
    "    Like the number of layers, try to increase the number of neurons gradually till it overfits the data. It is more simple and efficient to pick a model with more layers and more neurons than you actually need, and then use early stopping and other regularization techniques to prevent it from overfitting.\n",
    "\n",
    "In general, you get more bang for buck by increasing the number of layers than increasing the number of neurons per hidden layer.\n",
    "\n",
    "3. Learning rate, batch size, and other hyperparameters:\n",
    "- Learning rate: arguably the most important hyperparmeters\n",
    "In general, optimal learning rate is about half of the maximum learning rate.\n",
    "\n",
    "- Learning rate:\n",
    "    - train a model for a few hundred iterations starting with a very small learning rate and increasing it up to a very large value. Plot the loss function x learning rate \n",
    "    - the optimal learning rate is a bit lower than the point at which the loss starts to climb up. \n",
    "\n",
    "- Optimizer:\n",
    "    - Choose a better optimizer than plain old mini-batch gradient descent.\n",
    "    \n",
    "- Batch size:\n",
    "    - Try use a large batch size, use learning rate warm up, if training is unstable, then try using a small batch size. Literature shows contradictory results.\n",
    "    - Benefit of Large batch size : GPU can process efficiently\n",
    "    - Caveat of Large batch size : training instability especially in the beginning\n",
    "\n",
    "    - Benefit of Small batch size : generalize better than the model with large batch size\n",
    "    - Caveat of Small batch size : takes longer time to train\n",
    "\n",
    "- Activation funciton:\n",
    "    - Relu activation function is a good default. The activation function for the output layer depends on the task\n",
    "\n",
    "\n",
    "- Number of iterations:\n",
    "    - Number of iterations usually don't matter, just use early stopping instead\n",
    "\n",
    "** Learning rate and batch size are correlated. Thus, make sure to tweak both of them together.\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5f5c8a3209899e766b0d344da7f378c47efae6198cfb7cfdabe359cc9a92c262"
  },
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit ('handson-conda')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
